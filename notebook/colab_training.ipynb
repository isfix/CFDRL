{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f4a586eb",
            "metadata": {},
            "source": [
                "# Deep Multi-Pair Forex Trading System - Colab Training\n",
                "\n",
                "This notebook trains the LSTM-DQN model using data stored in your Google Drive.\n",
                "**Data Location:** `/content/drive/MyDrive/data/{symbol}.csv`\n",
                "\n",
                "### \u26a1 enable GPU\n",
                "To speed up training, ensure you really are using a GPU Runtime:\n",
                "1. In the menu, go to **Runtime** > **Change runtime type**.\n",
                "2. Select **T4 GPU** (or better) under Hardware accelerator.\n",
                "3. Click **Save**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d493a57",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gpu_check",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify GPU\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"\u2705 GPU Available: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f GPU NOT Detected! Please enable it in Runtime > Change runtime type.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9953daff",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install pandas_ta"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22c2809d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import pandas as pd\n",
                "import pandas_ta as ta\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "import os\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import random\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ccba8890",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIGURATION ---\n",
                "class Settings:\n",
                "    # --- TRADING PAIRS & PROFILES ---\n",
                "    # OPTIMIZATION: Zero Commission & Balanced Scaling\n",
                "    PAIR_CONFIGS = {\n",
                "        'XAUUSD': {\n",
                "            'spread': 0.20,\n",
                "            'commission': 0.0,       # Zero Comm\n",
                "            'scaling_factor': 5.0,   # Increased High Scaling for Gold (Difficulty Balance)\n",
                "            'contract_size': 100\n",
                "        },\n",
                "        'EURUSD': {\n",
                "            'spread': 0.0001,\n",
                "            'commission': 0.0,       # Zero Comm\n",
                "            'scaling_factor': 10000.0,\n",
                "            'contract_size': 100000\n",
                "        },\n",
                "        'GBPUSD': {\n",
                "            'spread': 0.0002,\n",
                "            'commission': 0.0,       # Zero Comm\n",
                "            'scaling_factor': 10000.0,\n",
                "            'contract_size': 100000\n",
                "        }\n",
                "    }\n",
                "    PAIRS = list(PAIR_CONFIGS.keys())\n",
                "    \n",
                "    # Core\n",
                "    SEQUENCE_LENGTH = 12 # Scalper: React to last hour only\n",
                "    # ADX added (Input Dim = 7)\n",
                "    FEATURES = ['log_ret', 'dist_ema', 'rsi', 'roc', 'volatility', 'hour', 'adx']\n",
                "    INPUT_DIM = len(FEATURES)\n",
                "    HIDDEN_DIM = 128\n",
                "    NUM_LAYERS = 2\n",
                "    DROPOUT = 0.2\n",
                "    OUTPUT_DIM = 3 \n",
                "\n",
                "    # Training\n",
                "    EPOCHS = 50 \n",
                "    BATCH_SIZE = 64\n",
                "    LEARNING_RATE = 0.001 # Aggressive Learning for Binary Scalper\n",
                "    GAMMA = 0.85  # Scalper: Greedy for immediate reward\n",
                "    EPSILON_START = 1.0\n",
                "    EPSILON_DECAY = 0.92\n",
                "    EPSILON_MIN = 0.01\n",
                "    \n",
                "    # Data\n",
                "    TRAIN_SPLIT_INDEX = 420000\n",
                "    ATR_PERIOD = 14"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b96fb512",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- MODEL (Brain) ---\n",
                "class QNetwork(nn.Module):\n",
                "    def __init__(self, input_dim=Settings.INPUT_DIM, \n",
                "                 hidden_dim=Settings.HIDDEN_DIM, \n",
                "                 num_layers=Settings.NUM_LAYERS, \n",
                "                 dropout=Settings.DROPOUT, \n",
                "                 output_dim=Settings.OUTPUT_DIM):\n",
                "        super(QNetwork, self).__init__()\n",
                "        \n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=input_dim,\n",
                "            hidden_size=hidden_dim,\n",
                "            num_layers=num_layers,\n",
                "            dropout=dropout if num_layers > 1 else 0,\n",
                "            batch_first=True\n",
                "        )\n",
                "        \n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(hidden_dim // 2, output_dim)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        lstm_out, _ = self.lstm(x)\n",
                "        last_step_out = lstm_out[:, -1, :]\n",
                "        q_values = self.fc(last_step_out)\n",
                "        return q_values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b9a79635",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- DATA PROCESSING ---\n",
                "def prepare_features(df):\n",
                "    df = df.copy()\n",
                "    # Log Returns (Scaled x1000)\n",
                "    df['log_ret'] = np.log(df['close'] / df['close'].shift(1)) * 1000.0\n",
                "    # EMA Distance (Scaled x1000)\n",
                "    ema50 = ta.ema(df['close'], length=50)\n",
                "    df['dist_ema'] = ((df['close'] - ema50) / df['close']) * 1000.0\n",
                "    # RSI\n",
                "    df['rsi'] = ta.rsi(df['close'], length=14) / 100.0\n",
                "    # ROC (Velocity) - Scaled x1000 (New \"Godlike\" Feature)\n",
                "    df['roc'] = ta.roc(df['close'], length=3) * 10.0\n",
                "    \n",
                "    # ADX (Trend Strength) - Range 0-100 -> Normalized 0-1\n",
                "    # 0-25: Choppy/Dead, 25+: Trending, 50+: Strong Trend\n",
                "    adx = ta.adx(df['high'], df['low'], df['close'], length=14)\n",
                "    # pandas_ta returns ADX_14, DMP_14, DMN_14\n",
                "    df['adx'] = adx['ADX_14'] / 100.0\n",
                "    \n",
                "    df.fillna(0, inplace=True) # FIXED: Handle NaNs from ROC & ADX\n",
                "    \n",
                "    # Volatility (Scaled x1000)\n",
                "    atr = ta.atr(df['high'], df['low'], df['close'], length=Settings.ATR_PERIOD)\n",
                "    df['volatility'] = (atr / df['close']) * 1000.0\n",
                "    # Time\n",
                "    df['hour'] = df.index.hour / 23.0\n",
                "\n",
                "    # Bollinger Bands\n",
                "    bb = ta.bbands(df['close'], length=20, std=2)\n",
                "    bb.columns = ['BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'BBB_20_2.0', 'BBP_20_2.0']\n",
                "    df = pd.concat([df, bb], axis=1)\n",
                "    \n",
                "    df.dropna(inplace=True)\n",
                "    return df\n",
                "\n",
                "class TradingDataset(Dataset):\n",
                "    def __init__(self, feature_data, close_prices, seq_len):\n",
                "        self.feature_data = feature_data\n",
                "        self.close_prices = close_prices\n",
                "        self.seq_len = seq_len\n",
                "        self.valid_indices = range(seq_len, len(feature_data) - 1)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.valid_indices)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        i = self.valid_indices[idx]\n",
                "        state_window = self.feature_data[i - self.seq_len : i]\n",
                "        next_state_window = self.feature_data[i - self.seq_len + 1 : i + 1]\n",
                "        curr_price = self.close_prices[i-1]\n",
                "        next_price = self.close_prices[i]\n",
                "\n",
                "        return {\n",
                "            'state': torch.FloatTensor(state_window),\n",
                "            'next_state': torch.FloatTensor(next_state_window),\n",
                "            'curr_price': torch.tensor(curr_price, dtype=torch.float32),\n",
                "            'next_price': torch.tensor(next_price, dtype=torch.float32)\n",
                "        }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6394cd99",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- TRAINING ENGINE ---\n",
                "def train_model(symbol, csv_path):\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    print(f\"Training {symbol} on {device}...\")\n",
                "    \n",
                "    # Load Profile Constants\n",
                "    if symbol not in Settings.PAIR_CONFIGS:\n",
                "         print(f\"Pair {symbol} not in config! Defaulting to XAUUSD.\")\n",
                "         profile = Settings.PAIR_CONFIGS['XAUUSD']\n",
                "    else:\n",
                "         profile = Settings.PAIR_CONFIGS[symbol]\n",
                "         \n",
                "    SCALING_FACTOR = profile['scaling_factor']\n",
                "    SPREAD = profile['spread']\n",
                "    COMMISSION = profile['commission']\n",
                "    \n",
                "    # Load Data\n",
                "    if not os.path.exists(csv_path):\n",
                "        print(f\"File {csv_path} not found.\")\n",
                "        return\n",
                "        \n",
                "    df = pd.read_csv(csv_path, parse_dates=['time'], index_col='time')\n",
                "    # FIX: Prepare Features BEFORE Dataset Creation\n",
                "    df = prepare_features(df)\n",
                "    \n",
                "    feature_data = df[Settings.FEATURES].values\n",
                "    close_prices = df['close'].values\n",
                "    \n",
                "    dataset = TradingDataset(feature_data, close_prices, Settings.SEQUENCE_LENGTH)\n",
                "    dataloader = DataLoader(dataset, batch_size=Settings.BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\n",
                "    \n",
                "    policy_net = QNetwork().to(device)\n",
                "    optimizer = optim.Adam(policy_net.parameters(), lr=Settings.LEARNING_RATE)\n",
                "    loss_fn = nn.MSELoss()\n",
                "    \n",
                "    epsilon = Settings.EPSILON_START\n",
                "    \n",
                "    loss_history = []\n",
                "    \n",
                "    for epoch in range(Settings.EPOCHS):\n",
                "        total_loss = 0\n",
                "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{Settings.EPOCHS}\")\n",
                "        \n",
                "        for batch in pbar:\n",
                "            state_tensor = batch['state'].to(device, non_blocking=True)\n",
                "            next_state_tensor = batch['next_state'].to(device, non_blocking=True)\n",
                "            curr_price = batch['curr_price'].to(device, non_blocking=True)\n",
                "            next_price = batch['next_price'].to(device, non_blocking=True)\n",
                "            \n",
                "            batch_size = state_tensor.size(0)\n",
                "            \n",
                "            # Epsilon Greedy\n",
                "            if random.random() < epsilon:\n",
                "                action_tensor = torch.randint(0, Settings.OUTPUT_DIM, (batch_size,), device=device)\n",
                "            else:\n",
                "                with torch.no_grad():\n",
                "                    q_values = policy_net(state_tensor)\n",
                "                    action_tensor = torch.argmax(q_values, dim=1)\n",
                "            \n",
                "            # --- Reward Calculation (Pip Normalization) ---\n",
                "            # 1. Normalized PnL\n",
                "            price_diff = next_price - curr_price\n",
                "            norm_pnl = price_diff * SCALING_FACTOR\n",
                "            \n",
                "            # 2. Normalized Costs\n",
                "            norm_spread = SPREAD * SCALING_FACTOR\n",
                "            norm_comm = COMMISSION * SCALING_FACTOR\n",
                "            total_cost = norm_spread + norm_comm\n",
                "            \n",
                "            # 3. Base Penalty\n",
                "            # HYBRID FIX: Small penalty to prevent laziness, but not force desperation.\n",
                "            base_penalty = -0.1\n",
                "            reward_tensor = torch.full((batch_size,), base_penalty, device=device)\n",
                "            \n",
                "            # Masks\n",
                "            is_buy = (action_tensor == 1)\n",
                "            is_sell = (action_tensor == 2)\n",
                "            \n",
                "            # 4. Final Reward Calculation (Hybrid Tanh)\n",
                "            # Tanh squashes result between -1 and 1.\n",
                "            # Small wins (0.1) -> ~0.1 reward\n",
                "            # Big wins (10.0) -> ~1.0 reward (Capped)\n",
                "            \n",
                "            # Buy Logic\n",
                "            buy_net = (norm_pnl - total_cost)\n",
                "            buy_final = torch.tanh(buy_net)\n",
                "            reward_tensor[is_buy] = buy_final[is_buy]\n",
                "            \n",
                "            # Sell Logic\n",
                "            sell_net = (-norm_pnl - total_cost)\n",
                "            sell_final = torch.tanh(sell_net)\n",
                "            reward_tensor[is_sell] = sell_final[is_sell]\n",
                "            \n",
                "            # Update\n",
                "            current_q = policy_net(state_tensor).gather(1, action_tensor.unsqueeze(1))\n",
                "            with torch.no_grad():\n",
                "                next_q = policy_net(next_state_tensor).max(1)[0]\n",
                "                target_q = reward_tensor + (Settings.GAMMA * next_q)\n",
                "                \n",
                "            loss = loss_fn(current_q.squeeze(1), target_q)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            \n",
                "        if epsilon > Settings.EPSILON_MIN:\n",
                "            epsilon *= Settings.EPSILON_DECAY\n",
                "            \n",
                "        avg_loss = total_loss / len(dataloader)\n",
                "        loss_history.append(avg_loss)\n",
                "        print(f\"Avg Loss: {avg_loss:.6f}, Epsilon: {epsilon:.4f}\")\n",
                "        \n",
                "    drive_save_path = os.path.join(os.path.dirname(csv_path), f\"{symbol}_brain.pth\")\n",
                "    torch.save(policy_net.state_dict(), drive_save_path)\n",
                "    print(f\"Model Saved to {drive_save_path}!\")\n",
                "    \n",
                "    plt.plot(loss_history)\n",
                "    plt.title(f\"Training Loss - {symbol}\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ca7fc7cf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- EXECUTION ---\n",
                "drive_data_path = \"/content/drive/MyDrive/data\"\n",
                "\n",
                "# \u26a1 SELECT PAIRS TO TRAIN HERE:\n",
                "pairs = ['EURUSD'] # Change to ['XAUUSD'] or Settings.PAIRS for all\n",
                "\n",
                "print(f\"Training Pairs: {pairs}\")\n",
                "\n",
                "for symbol in pairs:\n",
                "    csv_path = os.path.join(drive_data_path, f\"{symbol}.csv\")\n",
                "    if os.path.exists(csv_path):\n",
                "        print(f\"Found data for {symbol} at: {csv_path}\")\n",
                "        train_model(symbol, csv_path)\n",
                "    else:\n",
                "        print(f\"Data for {symbol} not found. Skipping.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "backtest_engine",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- BACKTEST ENGINE (Colab Version - Optimized) ---\n",
                "\n",
                "def colab_backtest(symbol, csv_path):\n",
                "    print(f\"\\n--- Starting Backtest for {symbol} ---\")\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    \n",
                "    model_path = os.path.join(os.path.dirname(csv_path), f\"{symbol}_brain.pth\")\n",
                "    \n",
                "    if not os.path.exists(model_path):\n",
                "        print(f\"Model {model_path} not found. Please train first.\")\n",
                "        return\n",
                "\n",
                "    policy_net = QNetwork().to(device)\n",
                "    try:\n",
                "        policy_net.load_state_dict(torch.load(model_path, map_location=device))\n",
                "    except RuntimeError as e:\n",
                "        print(f\"\\n!!! MODEL ARCHITECTURE MISMATCH !!!\")\n",
                "        print(f\"Error: {e}\")\n",
                "        print(f\"Cause: You are trying to load an OLD model (missing features) into the NEW code.\")\n",
                "        print(f\"Solution: You MUST run the 'TRAINING' cells above to retrain the model with the new features.\")\n",
                "        return\n",
                "        \n",
                "    policy_net.eval()\n",
                "    print(\"Model loaded.\")\n",
                "    \n",
                "    df = pd.read_csv(csv_path, parse_dates=['time'], index_col='time')\n",
                "    test_start_idx = Settings.TRAIN_SPLIT_INDEX \n",
                "    if len(df) < test_start_idx + 100:\n",
                "        print(f\"Not enough data for backtest. Total: {len(df)}, Needed: >{test_start_idx}\")\n",
                "        return\n",
                "        \n",
                "    print(f\"Backtesting on rows {test_start_idx} to {len(df)}...\")\n",
                "    \n",
                "    # FIX (Data Leakage): Prepare Features BEFORE Split\n",
                "    df = prepare_features(df)\n",
                "    \n",
                "    df_test = df.iloc[test_start_idx:].copy()\n",
                "    \n",
                "    feature_data = df_test[Settings.FEATURES].values\n",
                "    opens = df_test['open'].values\n",
                "    highs = df_test['high'].values\n",
                "    lows = df_test['low'].values\n",
                "    closes = df_test['close'].values\n",
                "    times = df_test.index\n",
                "    atrs = df_test['volatility'].values * closes\n",
                "\n",
                "    balance = 10000.0\n",
                "    equity_curve = [balance]\n",
                "    position = 0 \n",
                "    entry_price = 0.0\n",
                "    stop_loss = 0.0\n",
                "    \n",
                "    # Config Loading applied here\n",
                "    contract_size = 100\n",
                "    spread_cost = 0.20\n",
                "    txn_cost = 0.0\n",
                "    lot_size = 0.01\n",
                "    \n",
                "    if symbol in Settings.PAIR_CONFIGS:\n",
                "         profile = Settings.PAIR_CONFIGS[symbol]\n",
                "         contract_size = profile['contract_size']\n",
                "         spread_cost = profile['spread'] * contract_size * lot_size\n",
                "         txn_cost = profile['commission'] * contract_size * lot_size\n",
                "    \n",
                "    trades = []\n",
                "    \n",
                "    for t in tqdm(range(Settings.SEQUENCE_LENGTH, len(df_test) - 1)):\n",
                "        state_tensor = torch.FloatTensor(feature_data[t - Settings.SEQUENCE_LENGTH : t]).unsqueeze(0).to(device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            q = policy_net(state_tensor)\n",
                "            action = torch.argmax(q, dim=1).item()\n",
                "            \n",
                "            if action != 0: \n",
                "                 # --- FILTERS ---\n",
                "                 current_time = times[t]\n",
                "                 \n",
                "                 # 1. ADX FILTER (Dead Market Avoidance)\n",
                "                 # ADX is the LAST feature (index -1)\n",
                "                 # FIX: Index [0, -1, -1] for Scalar\n",
                "                 current_adx = state_tensor[0, -1, -1].item() * 100.0 # Un-normalize\n",
                "                 if current_adx < 25:\n",
                "                     action = 0 # Match is flat. Sit on hands.\n",
                "                 \n",
                "                 # 2. BOLLINGER SQUEEZE FILTER\n",
                "                 prev_time = times[t-1]\n",
                "                 try:\n",
                "                     bb_u = df_test.loc[prev_time, 'BBU_20_2.0']\n",
                "                     bb_l = df_test.loc[prev_time, 'BBL_20_2.0']\n",
                "                     prev_close = df_test.loc[prev_time, 'close']\n",
                "                         \n",
                "                     width = bb_u - bb_l\n",
                "                     vol_pct = width / prev_close\n",
                "                     if vol_pct < 0.0005:\n",
                "                          action = 0\n",
                "                 except KeyError:\n",
                "                     pass\n",
                "            \n",
                "        # Execution at Open t\n",
                "        next_open = opens[t]\n",
                "        next_high = highs[t]\n",
                "        next_low = lows[t]\n",
                "        next_time = times[t]\n",
                "        atr = atrs[t-1] \n",
                "        \n",
                "        trade_closed = False\n",
                "        exit_price = 0.0\n",
                "        \n",
                "        if position != 0:\n",
                "            # Time Hard Exit (20:00)\n",
                "            if next_time.hour >= 20 and next_time.minute == 0:\n",
                "                exit_price = next_open\n",
                "                trade_closed = True\n",
                "            elif position == 1:\n",
                "                 if next_low <= stop_loss:\n",
                "                      exit_price = stop_loss\n",
                "                      trade_closed = True\n",
                "                 elif (next_high - entry_price) > (1.0 * atr) and stop_loss < entry_price:\n",
                "                      stop_loss = entry_price\n",
                "            elif position == -1:\n",
                "                 if next_high >= stop_loss:\n",
                "                      exit_price = stop_loss\n",
                "                      trade_closed = True\n",
                "                 elif (entry_price - next_low) > (1.0 * atr) and stop_loss > entry_price:\n",
                "                      stop_loss = entry_price\n",
                "                \n",
                "            if trade_closed:\n",
                "                if position == 1:\n",
                "                     gross_pnl = (exit_price - entry_price) * contract_size * lot_size\n",
                "                else:\n",
                "                     gross_pnl = (entry_price - exit_price) * contract_size * lot_size\n",
                "                     \n",
                "                net_pnl = gross_pnl - txn_cost\n",
                "                balance += net_pnl\n",
                "                trades.append(net_pnl)\n",
                "                position = 0\n",
                "        \n",
                "        if not trade_closed:\n",
                "            if action == 1: \n",
                "                if position == -1: \n",
                "                     exit_price = next_open\n",
                "                     gross_pnl = (entry_price - exit_price) * contract_size * lot_size\n",
                "                     net_pnl = gross_pnl - txn_cost\n",
                "                     balance += net_pnl\n",
                "                     trades.append(net_pnl)\n",
                "                     \n",
                "                     position = 1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price - (atr * 2.5)\n",
                "                elif position == 0:\n",
                "                     position = 1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price - (atr * 2.5)\n",
                "            elif action == 2: \n",
                "                if position == 1: \n",
                "                     exit_price = next_open\n",
                "                     gross_pnl = (exit_price - entry_price) * contract_size * lot_size\n",
                "                     net_pnl = gross_pnl - txn_cost\n",
                "                     balance += net_pnl\n",
                "                     trades.append(net_pnl)\n",
                "                     \n",
                "                     position = -1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price + (atr * 2.5)\n",
                "                elif position == 0:\n",
                "                     position = -1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price + (atr * 2.5)\n",
                "                     \n",
                "        equity_curve.append(balance)\n",
                "        \n",
                "    win_rate = sum(1 for t in trades if t > 0) / len(trades) * 100 if trades else 0\n",
                "    print(f\"\\nFinal Balance: ${balance:.2f}\")\n",
                "    print(f\"Total Trades: {len(trades)}\")\n",
                "    print(f\"Win Rate: {win_rate:.1f}%\")\n",
                "    \n",
                "    plt.figure(figsize=(12,6))\n",
                "    plt.plot(equity_curve)\n",
                "    plt.title(f\"Backtest Equity - {symbol}\")\n",
                "    plt.show()\n",
                "\n",
                "for symbol in Settings.PAIRS:\n",
                "     csv_path = os.path.join(drive_data_path, f\"{symbol}.csv\")\n",
                "     if os.path.exists(csv_path):\n",
                "         colab_backtest(symbol, csv_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}