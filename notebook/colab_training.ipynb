{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f4a586eb",
            "metadata": {},
            "source": [
                "# Deep Multi-Pair Forex Trading System - Colab Training\n",
                "\n",
                "This notebook trains the LSTM-DQN model using data stored in your Google Drive.\n",
                "**Data Location:** `/content/drive/MyDrive/data/{symbol}.csv`\n",
                "\n",
                "### \u26a1 enable GPU\n",
                "To speed up training, ensure you really are using a GPU Runtime:\n",
                "1. In the menu, go to **Runtime** > **Change runtime type**.\n",
                "2. Select **T4 GPU** (or better) under Hardware accelerator.\n",
                "3. Click **Save**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d493a57",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gpu_check",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify GPU\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"\u2705 GPU Available: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f GPU NOT Detected! Please enable it in Runtime > Change runtime type.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9953daff",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install pandas_ta"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22c2809d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import pandas as pd\n",
                "import pandas_ta as ta\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "import os\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import random\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ccba8890",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIGURATION ---\n",
                "class Settings:\n",
                "    PAIRS = ['XAUUSD', 'EURUSD', 'GBPUSD'] \n",
                "    \n",
                "    # Core\n",
                "    SEQUENCE_LENGTH = 60\n",
                "    FEATURES = ['log_ret', 'dist_ema', 'rsi', 'volatility', 'hour']\n",
                "    INPUT_DIM = len(FEATURES)\n",
                "    HIDDEN_DIM = 128\n",
                "    NUM_LAYERS = 2\n",
                "    DROPOUT = 0.2\n",
                "    OUTPUT_DIM = 3 \n",
                "\n",
                "    # Training\n",
                "    EPOCHS = 50 # Increased to give more time to converge\n",
                "    BATCH_SIZE = 64\n",
                "    LEARNING_RATE = 0.001\n",
                "    GAMMA = 0.99\n",
                "    EPSILON_START = 1.0\n",
                "    EPSILON_DECAY = 0.92 # Faster decay so it stops acting randomly sooner\n",
                "    EPSILON_MIN = 0.01\n",
                "    \n",
                "    # Data\n",
                "    TRAIN_SPLIT_INDEX = 420000\n",
                "    ATR_PERIOD = 14"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b96fb512",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- MODEL (Brain) ---\n",
                "class QNetwork(nn.Module):\n",
                "    def __init__(self, input_dim=Settings.INPUT_DIM, \n",
                "                 hidden_dim=Settings.HIDDEN_DIM, \n",
                "                 num_layers=Settings.NUM_LAYERS, \n",
                "                 dropout=Settings.DROPOUT, \n",
                "                 output_dim=Settings.OUTPUT_DIM):\n",
                "        super(QNetwork, self).__init__()\n",
                "        \n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=input_dim,\n",
                "            hidden_size=hidden_dim,\n",
                "            num_layers=num_layers,\n",
                "            dropout=dropout if num_layers > 1 else 0,\n",
                "            batch_first=True\n",
                "        )\n",
                "        \n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(hidden_dim // 2, output_dim)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        lstm_out, _ = self.lstm(x)\n",
                "        last_step_out = lstm_out[:, -1, :]\n",
                "        q_values = self.fc(last_step_out)\n",
                "        return q_values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b9a79635",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- DATA PROCESSING ---\n",
                "def prepare_features(df):\n",
                "    df = df.copy()\n",
                "    # Log Returns\n",
                "    df['log_ret'] = np.log(df['close'] / df['close'].shift(1))\n",
                "    # EMA Distance\n",
                "    ema50 = ta.ema(df['close'], length=50)\n",
                "    df['dist_ema'] = (df['close'] - ema50) / df['close']\n",
                "    # RSI\n",
                "    df['rsi'] = ta.rsi(df['close'], length=14) / 100.0\n",
                "    # Volatility\n",
                "    atr = ta.atr(df['high'], df['low'], df['close'], length=Settings.ATR_PERIOD)\n",
                "    df['volatility'] = atr / df['close']\n",
                "    # Time\n",
                "    df['hour'] = df.index.hour / 23.0\n",
                "\n",
                "    # Bollinger Bands (Step 3: Squeeze Filter)\n",
                "    # Appends BBL_20_2.0, BBM_20_2.0, BBU_20_2.0\n",
                "    bb = ta.bbands(df['close'], length=20, std=2)\n",
                "    df = pd.concat([df, bb], axis=1)\n",
                "    \n",
                "    df.dropna(inplace=True)\n",
                "    return df\n",
                "\n",
                "class TradingDataset(Dataset):\n",
                "    def __init__(self, feature_data, close_prices, seq_len):\n",
                "        self.feature_data = feature_data\n",
                "        self.close_prices = close_prices\n",
                "        self.seq_len = seq_len\n",
                "        self.valid_indices = range(seq_len, len(feature_data) - 1)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.valid_indices)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        i = self.valid_indices[idx]\n",
                "        state_window = self.feature_data[i - self.seq_len : i]\n",
                "        next_state_window = self.feature_data[i - self.seq_len + 1 : i + 1]\n",
                "        curr_price = self.close_prices[i-1]\n",
                "        next_price = self.close_prices[i]\n",
                "\n",
                "        return {\n",
                "            'state': torch.FloatTensor(state_window),\n",
                "            'next_state': torch.FloatTensor(next_state_window),\n",
                "            'curr_price': torch.tensor(curr_price, dtype=torch.float32),\n",
                "            'next_price': torch.tensor(next_price, dtype=torch.float32)\n",
                "        }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6394cd99",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- TRAINING ENGINE ---\n",
                "def train_model(symbol, csv_path):\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    print(f\"Training {symbol} on {device}...\")\n",
                "    \n",
                "    # Load Data\n",
                "    if not os.path.exists(csv_path):\n",
                "        print(f\"File {csv_path} not found.\")\n",
                "        return\n",
                "        \n",
                "    df = pd.read_csv(csv_path, parse_dates=['time'], index_col='time')\n",
                "    df = prepare_features(df)\n",
                "    \n",
                "    feature_data = df[Settings.FEATURES].values\n",
                "    close_prices = df['close'].values\n",
                "    \n",
                "    dataset = TradingDataset(feature_data, close_prices, Settings.SEQUENCE_LENGTH)\n",
                "    # OPTIMIZATION: pin_memory=True for faster CPU->GPU transfer\n",
                "    dataloader = DataLoader(dataset, batch_size=Settings.BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\n",
                "    \n",
                "    policy_net = QNetwork().to(device)\n",
                "    optimizer = optim.Adam(policy_net.parameters(), lr=Settings.LEARNING_RATE)\n",
                "    loss_fn = nn.MSELoss()\n",
                "    \n",
                "    epsilon = Settings.EPSILON_START\n",
                "    \n",
                "    loss_history = []\n",
                "    \n",
                "    for epoch in range(Settings.EPOCHS):\n",
                "        total_loss = 0\n",
                "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{Settings.EPOCHS}\")\n",
                "        \n",
                "        for batch in pbar:\n",
                "            # Move to device (GPU)\n",
                "            state_tensor = batch['state'].to(device, non_blocking=True)\n",
                "            next_state_tensor = batch['next_state'].to(device, non_blocking=True)\n",
                "            curr_price = batch['curr_price'].to(device, non_blocking=True)\n",
                "            next_price = batch['next_price'].to(device, non_blocking=True)\n",
                "            \n",
                "            batch_size = state_tensor.size(0)\n",
                "            \n",
                "            # Epsilon Greedy\n",
                "            if random.random() < epsilon:\n",
                "                action_tensor = torch.randint(0, Settings.OUTPUT_DIM, (batch_size,), device=device)\n",
                "            else:\n",
                "                with torch.no_grad():\n",
                "                    q_values = policy_net(state_tensor)\n",
                "                    action_tensor = torch.argmax(q_values, dim=1)\n",
                "            \n",
                "            # Reward Logic (Solution 1 & 3 & Pip Scaling)\n",
                "            # 1. Scaling Factor (Fix for EURUSD 'Decimal Dust')\n",
                "            if \"USD\" in symbol and \"XAU\" not in symbol:\n",
                "                 SCALING_FACTOR = 10000.0 # Forex (EURUSD, GBPUSD) -> 1 pip = 1.0\n",
                "                 spread_cost_per_unit = 0.0001\n",
                "            else: \n",
                "                 SCALING_FACTOR = 1.0 # Gold/Indices -> $1 = 1.0 (Approx)\n",
                "                 spread_cost_per_unit = 0.20 # Gold Spread\n",
                "\n",
                "            price_diff = next_price - curr_price\n",
                "            \n",
                "            # 2. Base Penalty (Holding Cost)\n",
                "            # We scale the penalty too so it hurts\n",
                "            base_penalty = -0.1 * (spread_cost_per_unit * SCALING_FACTOR)\n",
                "            reward_tensor = torch.full((batch_size,), base_penalty, device=device)\n",
                "            \n",
                "            # Masks\n",
                "            is_buy = (action_tensor == 1)\n",
                "            is_sell = (action_tensor == 2)\n",
                "            \n",
                "            # Pnl Calculation (Scaled)\n",
                "            # (Change - Cost) * Scale\n",
                "            buy_pnl = (price_diff - spread_cost_per_unit) * SCALING_FACTOR\n",
                "            sell_pnl = (-price_diff - spread_cost_per_unit) * SCALING_FACTOR\n",
                "            \n",
                "            # 3. Reward Scaling (The Carrot)\n",
                "            # If PnL > 0, multiply buy 10.0\n",
                "            bias_scaler = 10.0\n",
                "            \n",
                "            # Buy Rewards\n",
                "            final_buy = torch.where(buy_pnl > 0, buy_pnl * bias_scaler, buy_pnl)\n",
                "            reward_tensor[is_buy] = final_buy[is_buy]\n",
                "            \n",
                "            # Sell Rewards \n",
                "            final_sell = torch.where(sell_pnl > 0, sell_pnl * bias_scaler, sell_pnl)\n",
                "            reward_tensor[is_sell] = final_sell[is_sell]\n",
                "            \n",
                "            # Update\n",
                "            current_q = policy_net(state_tensor).gather(1, action_tensor.unsqueeze(1))\n",
                "            with torch.no_grad():\n",
                "                next_q = policy_net(next_state_tensor).max(1)[0]\n",
                "                target_q = reward_tensor + (Settings.GAMMA * next_q)\n",
                "                \n",
                "            loss = loss_fn(current_q.squeeze(1), target_q)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            \n",
                "        if epsilon > Settings.EPSILON_MIN:\n",
                "            epsilon *= Settings.EPSILON_DECAY\n",
                "            \n",
                "        avg_loss = total_loss / len(dataloader)\n",
                "        loss_history.append(avg_loss)\n",
                "        print(f\"Avg Loss: {avg_loss:.6f}, Epsilon: {epsilon:.4f}\")\n",
                "        \n",
                "    # Save Model to Google Drive (same folder as data)\n",
                "    drive_save_path = os.path.join(os.path.dirname(csv_path), f\"{symbol}_brain.pth\")\n",
                "    torch.save(policy_net.state_dict(), drive_save_path)\n",
                "    print(f\"Model Saved to {drive_save_path}!\")\n",
                "    \n",
                "    plt.plot(loss_history)\n",
                "    plt.title(f\"Training Loss - {symbol}\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ca7fc7cf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- EXECUTION ---\n",
                "\n",
                "# Using Google Drive Path\n",
                "drive_data_path = \"/content/drive/MyDrive/data\"\n",
                "\n",
                "pairs = ['XAUUSD', 'EURUSD', 'GBPUSD'] # Added other pairs\n",
                "\n",
                "for symbol in pairs:\n",
                "    # Look for file in the specific Drive location\n",
                "    csv_path = os.path.join(drive_data_path, f\"{symbol}.csv\")\n",
                "    \n",
                "    if os.path.exists(csv_path):\n",
                "        print(f\"Found data for {symbol} at: {csv_path}\")\n",
                "        train_model(symbol, csv_path)\n",
                "    else:\n",
                "        print(f\"Data for {symbol} not found. Skipping.\")\n",
                "    \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "backtest_engine",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- BACKTEST ENGINE (Colab Version) ---\n",
                "# This runs immediately after training to verify performance on the Test Split\n",
                "\n",
                "def colab_backtest(symbol, csv_path):\n",
                "    print(f\"\\n--- Starting Backtest for {symbol} ---\")\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    \n",
                "    # Path to the model we just trained/saved\n",
                "    model_path = os.path.join(os.path.dirname(csv_path), f\"{symbol}_brain.pth\")\n",
                "    \n",
                "    if not os.path.exists(model_path):\n",
                "        print(f\"Model {model_path} not found. Please train first.\")\n",
                "        return\n",
                "\n",
                "    # Load Model\n",
                "    policy_net = QNetwork().to(device)\n",
                "    policy_net.load_state_dict(torch.load(model_path, map_location=device))\n",
                "    policy_net.eval()\n",
                "    print(\"Model loaded.\")\n",
                "    \n",
                "    # Load Data\n",
                "    df = pd.read_csv(csv_path, parse_dates=['time'], index_col='time')\n",
                "    \n",
                "    # Split Test Data (Using strict index from Settings)\n",
                "    test_start_idx = Settings.TRAIN_SPLIT_INDEX \n",
                "    if len(df) < test_start_idx + 100:\n",
                "        print(f\"Not enough data for backtest. Total: {len(df)}, Needed: >{test_start_idx}\")\n",
                "        return\n",
                "        \n",
                "    print(f\"Backtesting on rows {test_start_idx} to {len(df)}...\")\n",
                "    df_test = df.iloc[test_start_idx:].copy()\n",
                "    df_test = prepare_features(df_test)\n",
                "    \n",
                "    # Prepare Vectors\n",
                "    feature_data = df_test[Settings.FEATURES].values\n",
                "    opens = df_test['open'].values\n",
                "    highs = df_test['high'].values\n",
                "    lows = df_test['low'].values\n",
                "    closes = df_test['close'].values\n",
                "    times = df_test.index\n",
                "    atrs = df_test['volatility'].values * closes\n",
                "\n",
                "    # BB Columns for Filter\n",
                "    bb_u = df_test['BBU_20_2.0'].values\n",
                "    bb_l = df_test['BBL_20_2.0'].values\n",
                "    \n",
                "    # Simulation State\n",
                "    balance = 10000.0\n",
                "    equity_curve = [balance]\n",
                "    position = 0 # 0=None, 1=Long, -1=Short\n",
                "    entry_price = 0.0\n",
                "    stop_loss = 0.0\n",
                "    \n",
                "    # Costs (Dynamic based on Symbol)\n",
                "    if \"USD\" in symbol and \"XAU\" not in symbol:\n",
                "         # Forex (EURUSD, GBPUSD)\n",
                "         contract_size = 100000 \n",
                "         self_spread_cost_per_trade = 0.10 \n",
                "         txn_cost = 0.15\n",
                "    else:\n",
                "         # Gold (XAUUSD)\n",
                "         contract_size = 100 \n",
                "         self_spread_cost_per_trade = 0.20 \n",
                "         txn_cost = 0.27\n",
                "    \n",
                "    trades = []\n",
                "    \n",
                "    for t in tqdm(range(Settings.SEQUENCE_LENGTH, len(df_test) - 1)):\n",
                "        # State Input\n",
                "        state_tensor = torch.FloatTensor(feature_data[t - Settings.SEQUENCE_LENGTH : t]).unsqueeze(0).to(device)\n",
                "        \n",
                "        # Model Decision\n",
                "        with torch.no_grad():\n",
                "            q = policy_net(state_tensor)\n",
                "            \n",
                "            # PROBABILITY FILTER (Fix 1: Confidence > 0.60)\n",
                "            probs = torch.nn.functional.softmax(q, dim=1)\n",
                "            confidence, action = torch.max(probs, dim=1)\n",
                "            \n",
                "            action = action.item()\n",
                "            confidence = confidence.item()\n",
                "            \n",
                "            if action != 0 and confidence < 0.60:\n",
                "                action = 0 # VETO: Low Confidence\n",
                "\n",
                "            # --- FILTERS (Asset Personality Fix) ---\n",
                "            if action != 0: # Only filter if trying to trade\n",
                "                 current_time = times[t]\n",
                "                 \n",
                "                 # 1. TIME FILTER (EURUSD Kill Switch)\n",
                "                 # Only trade 08:00 - 17:00\n",
                "                 if \"USD\" in symbol and \"XAU\" not in symbol:\n",
                "                      if current_time.hour < 8 or current_time.hour > 17:\n",
                "                           action = 0\n",
                "                 \n",
                "                 # 2. BOLLINGER SQUEEZE FILTER\n",
                "                 # If volatility < 0.05%, kill it\n",
                "                 width = bb_u[t] - bb_l[t]\n",
                "                 vol_pct = width / closes[t]\n",
                "                 if vol_pct < 0.0005:\n",
                "                      action = 0\n",
                "            \n",
                "        # Market Data at Next Open (Execution)\n",
                "        next_open = opens[t+1]\n",
                "        next_high = highs[t+1]\n",
                "        next_low = lows[t+1]\n",
                "        next_time = times[t+1]\n",
                "        atr = atrs[t]\n",
                "        \n",
                "        # --- 1. Exits (SL / Time / Breakeven) ---\n",
                "        trade_closed = False\n",
                "        exit_price = 0.0\n",
                "        \n",
                "        if position != 0:\n",
                "            # Time Hard Exit (20:00)\n",
                "            if next_time.hour >= 20 and next_time.minute == 0:\n",
                "                exit_price = next_open\n",
                "                trade_closed = True\n",
                "            \n",
                "            # SL Check\n",
                "            elif position == 1:\n",
                "                 if next_low <= stop_loss:\n",
                "                      exit_price = stop_loss\n",
                "                      trade_closed = True\n",
                "                 # Breakeven\n",
                "                 elif (next_high - entry_price) > (1.0 * atr) and stop_loss < entry_price:\n",
                "                      stop_loss = entry_price\n",
                "\n",
                "            elif position == -1:\n",
                "                 if next_high >= stop_loss:\n",
                "                      exit_price = stop_loss\n",
                "                      trade_closed = True\n",
                "                 # Breakeven\n",
                "                 elif (entry_price - next_low) > (1.0 * atr) and stop_loss > entry_price:\n",
                "                      stop_loss = entry_price\n",
                "                \n",
                "            if trade_closed:\n",
                "                # Calculate PnL (Standardized)\n",
                "                if position == 1:\n",
                "                     gross_pnl = (exit_price - entry_price) * contract_size * lot_size\n",
                "                else:\n",
                "                     gross_pnl = (entry_price - exit_price) * contract_size * lot_size\n",
                "                     \n",
                "                net_pnl = gross_pnl - txn_cost\n",
                "                balance += net_pnl\n",
                "                trades.append(net_pnl)\n",
                "                position = 0\n",
                "        \n",
                "        # --- 2. Entries ---\n",
                "        if not trade_closed:\n",
                "            if action == 1: # Buy Signal\n",
                "                if position == -1: # Reverse\n",
                "                     exit_price = next_open\n",
                "                     gross_pnl = (entry_price - exit_price) * contract_size * lot_size\n",
                "                     net_pnl = gross_pnl - txn_cost\n",
                "                     balance += net_pnl\n",
                "                     trades.append(net_pnl)\n",
                "                     \n",
                "                     position = 1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price - (atr * 2.5)\n",
                "                elif position == 0:\n",
                "                     position = 1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price - (atr * 2.5)\n",
                "            \n",
                "            elif action == 2: # Sell Signal\n",
                "                if position == 1: # Reverse\n",
                "                     exit_price = next_open\n",
                "                     gross_pnl = (exit_price - entry_price) * contract_size * lot_size\n",
                "                     net_pnl = gross_pnl - txn_cost\n",
                "                     balance += net_pnl\n",
                "                     trades.append(net_pnl)\n",
                "                     \n",
                "                     position = -1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price + (atr * 2.5)\n",
                "                elif position == 0:\n",
                "                     position = -1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price + (atr * 2.5)\n",
                "                     \n",
                "        equity_curve.append(balance)\n",
                "        \n",
                "    # Stats\n",
                "    win_rate = sum(1 for t in trades if t > 0) / len(trades) * 100 if trades else 0\n",
                "    print(f\"\\nFinal Balance: ${balance:.2f}\")\n",
                "    print(f\"Total Trades: {len(trades)}\")\n",
                "    print(f\"Win Rate: {win_rate:.1f}%\")\n",
                "    \n",
                "    plt.figure(figsize=(12,6))\n",
                "    plt.plot(equity_curve)\n",
                "    plt.title(f\"Backtest Equity - {symbol}\")\n",
                "    plt.show()\n",
                "\n",
                "# Run Backtest for all pairs\n",
                "for symbol in pairs:\n",
                "     csv_path = os.path.join(drive_data_path, f\"{symbol}.csv\")\n",
                "     if os.path.exists(csv_path):\n",
                "         colab_backtest(symbol, csv_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}