{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Trading Bot Training (Colab)\n",
                "**35 Features** | **M15 Timeframe** | **Semantic Actions** | **Position-Aware QNetwork**\n",
                "\n",
                "Upload your EURUSD M5 CSV (columns: time, open, high, low, close, tick_volume) to `/content/`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== SETTINGS ====================\n",
                "class Settings:\n",
                "    # V2 Feature Set (35 features, alpha-proven at 55.1%)\n",
                "    FEATURES = [\n",
                "        'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos',\n",
                "        'session_london', 'session_nyc',\n",
                "        'ret_1', 'ret_5', 'ret_20', 'rsi_14', 'roc_10',\n",
                "        'zscore_20', 'zscore_50', 'bb_position', 'vwap_deviation',\n",
                "        'dist_ema_20', 'dist_ema_50', 'ema_slope_20', 'adx_14',\n",
                "        'atr_normalized', 'bb_width', 'volatility_ratio', 'atr_percentile',\n",
                "        'body_ratio', 'upper_wick_ratio', 'lower_wick_ratio',\n",
                "        'volume_ratio', 'volume_trend', 'price_volume_corr',\n",
                "        'dist_session_high', 'dist_session_low',\n",
                "        'session_range_position', 'session_range_ratio',\n",
                "        'h1_trend', 'h1_momentum',\n",
                "    ]\n",
                "    INPUT_DIM = len(FEATURES)  # 35\n",
                "    SEQUENCE_LENGTH = 48       # 12 hours of M15\n",
                "    ENCODER_DIM = 64\n",
                "    HIDDEN_DIM = 128\n",
                "    NUM_LAYERS = 2\n",
                "    DROPOUT = 0.25\n",
                "    OUTPUT_DIM = 4             # HOLD, BUY, SELL, CLOSE\n",
                "    ACTION_NAMES = ['HOLD', 'BUY', 'SELL', 'CLOSE']\n",
                "    TRADE_STATE_DIM = 3        # position, bars_held, unrealized_pnl\n",
                "\n",
                "    # Training\n",
                "    EPOCHS = 10\n",
                "    BATCH_SIZE = 64\n",
                "    LEARNING_RATE = 0.0003\n",
                "    GAMMA = 0.95\n",
                "    EPSILON_START = 1.0\n",
                "    EPSILON_DECAY_STEPS = 750_000  # Linear decay: reach min at step 750k\n",
                "    EPSILON_MIN = 0.05\n",
                "    TARGET_UPDATE_FREQ = 500\n",
                "    TAU = 0.005\n",
                "    TRANSACTION_COST_BPS = 2\n",
                "    TRADE_PENALTY = 0.5        # Fixed penalty per position change\n",
                "    HOLD_BONUS = 0.1           # Bonus for patient holding (>4 bars)\n",
                "    HOLD_BONUS_MIN_BARS = 4    # Min bars held before bonus\n",
                "    REWARD_CLIP = 10.0\n",
                "    SCALING_FACTOR = 10000.0   # For EURUSD\n",
                "    PER_ALPHA = 0.6\n",
                "    PER_BETA_START = 0.4\n",
                "    MEMORY_CAPACITY = 100000\n",
                "    EARLY_STOP_PATIENCE = 10\n",
                "    EPISODE_LENGTH = 2000      # ~21 days M15 â€” enough for trade lifecycle\n",
                "    EPISODES_PER_EPOCH = 50    # 50x2000 = 100k steps/epoch\n",
                "\n",
                "    # Data\n",
                "    CSV_PATH = '/content/EURUSD_M5.csv'  # Upload your CSV here\n",
                "    PAIR = 'EURUSD'\n",
                "\n",
                "print(f'Settings loaded: {Settings.INPUT_DIM} features, {Settings.OUTPUT_DIM} actions')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import pandas_ta as ta\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import copy\n",
                "import random\n",
                "import os\n",
                "import gc\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Device: {device}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## V2 Feature Engineering (35 features)\n",
                "Time structure, VWAP, session context, volume dynamics, multi-TF context"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def resample_ohlcv(df, rule='15min'):\n",
                "    agg = {'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last'}\n",
                "    if 'tick_volume' in df.columns: agg['tick_volume'] = 'sum'\n",
                "    return df.resample(rule).agg(agg).dropna()\n",
                "\n",
                "def prepare_features(df):\n",
                "    df = df.copy()\n",
                "    if not isinstance(df.index, pd.DatetimeIndex):\n",
                "        if 'time' in df.columns:\n",
                "            df['time'] = pd.to_datetime(df['time'])\n",
                "            df.set_index('time', inplace=True)\n",
                "\n",
                "    # 1. TIME STRUCTURE\n",
                "    hour = df.index.hour + df.index.minute / 60.0\n",
                "    df['hour_sin'] = np.sin(2 * np.pi * hour / 24.0)\n",
                "    df['hour_cos'] = np.cos(2 * np.pi * hour / 24.0)\n",
                "    dow = df.index.dayofweek\n",
                "    df['dow_sin'] = np.sin(2 * np.pi * dow / 5.0)\n",
                "    df['dow_cos'] = np.cos(2 * np.pi * dow / 5.0)\n",
                "    utc_hour = df.index.hour\n",
                "    df['session_london'] = ((utc_hour >= 7) & (utc_hour < 16)).astype(float)\n",
                "    df['session_nyc'] = ((utc_hour >= 13) & (utc_hour < 22)).astype(float)\n",
                "\n",
                "    # 2. BASE\n",
                "    atr = ta.atr(df['high'], df['low'], df['close'], length=14)\n",
                "    df['atr'] = atr.bfill().fillna(df['close'] * 0.001)\n",
                "\n",
                "    # 3. RETURNS & MOMENTUM\n",
                "    for lag in [1, 5, 20]:\n",
                "        raw_ret = df['close'].pct_change(lag)\n",
                "        rm = raw_ret.rolling(60).mean()\n",
                "        rs = raw_ret.rolling(60).std().replace(0, np.nan).fillna(raw_ret.std())\n",
                "        df[f'ret_{lag}'] = (raw_ret - rm) / rs\n",
                "    rsi = ta.rsi(df['close'], length=14)\n",
                "    df['rsi_14'] = (rsi / 100.0) if rsi is not None else 0.5\n",
                "    roc = ta.roc(df['close'], length=10)\n",
                "    df['roc_10'] = (roc / 100.0) if roc is not None else 0.0\n",
                "\n",
                "    # 4. MEAN REVERSION\n",
                "    for w in [20, 50]:\n",
                "        rm = df['close'].rolling(w).mean()\n",
                "        rs = df['close'].rolling(w).std().replace(0, np.nan).fillna(1e-8)\n",
                "        df[f'zscore_{w}'] = (df['close'] - rm) / rs\n",
                "    bb = ta.bbands(df['close'], length=20, std=2)\n",
                "    if bb is not None and not bb.empty:\n",
                "        bbl, bbm, bbu = bb.iloc[:, 0], bb.iloc[:, 1], bb.iloc[:, 2]\n",
                "        bb_range = (bbu - bbl).replace(0, np.nan).fillna(1e-8)\n",
                "        df['bb_position'] = (df['close'] - bbl) / bb_range\n",
                "        df['bb_width'] = (bbu - bbl) / df['close']\n",
                "    else:\n",
                "        df['bb_position'], df['bb_width'] = 0.5, 0.0\n",
                "\n",
                "    # VWAP\n",
                "    vol_col = 'tick_volume' if 'tick_volume' in df.columns else None\n",
                "    tv = df[vol_col].astype(float).replace(0, 1) if vol_col else pd.Series(1.0, index=df.index)\n",
                "    tp = (df['high'] + df['low'] + df['close']) / 3.0\n",
                "    dg = df.index.date\n",
                "    cum_tp_vol = (tp * tv).groupby(dg).cumsum()\n",
                "    cum_vol = tv.groupby(dg).cumsum().replace(0, np.nan).fillna(1)\n",
                "    vwap = cum_tp_vol / cum_vol\n",
                "    df['vwap_deviation'] = (df['close'] - vwap) / df['atr']\n",
                "\n",
                "    # 5. TREND\n",
                "    ema_20 = ta.ema(df['close'], length=20)\n",
                "    ema_50 = ta.ema(df['close'], length=50)\n",
                "    df['dist_ema_20'] = (df['close'] - ema_20) / df['atr']\n",
                "    df['dist_ema_50'] = (df['close'] - ema_50) / df['atr']\n",
                "    df['ema_slope_20'] = (ema_20 - ema_20.shift(5)) / df['atr']\n",
                "    adx_df = ta.adx(df['high'], df['low'], df['close'], length=14)\n",
                "    df['adx_14'] = (adx_df.iloc[:, 0] / 100.0) if adx_df is not None and not adx_df.empty else 0.0\n",
                "\n",
                "    # 6. VOLATILITY\n",
                "    df['atr_normalized'] = df['atr'] / df['close']\n",
                "    rv = df['close'].pct_change().rolling(20).std()\n",
                "    rv_mean = rv.rolling(100).mean().replace(0, np.nan).fillna(rv.mean())\n",
                "    df['volatility_ratio'] = rv / rv_mean\n",
                "    atr_min = df['atr'].rolling(100, min_periods=1).min()\n",
                "    atr_max = df['atr'].rolling(100, min_periods=1).max()\n",
                "    atr_range = (atr_max - atr_min).replace(0, np.nan).fillna(1e-8)\n",
                "    df['atr_percentile'] = (df['atr'] - atr_min) / atr_range\n",
                "\n",
                "    # 7. CANDLE\n",
                "    df['body_ratio'] = (df['close'] - df['open']) / df['atr']\n",
                "    df['upper_wick_ratio'] = (df['high'] - df[['open','close']].max(axis=1)) / df['atr']\n",
                "    df['lower_wick_ratio'] = (df[['open','close']].min(axis=1) - df['low']) / df['atr']\n",
                "\n",
                "    # 8. VOLUME\n",
                "    if vol_col:\n",
                "        vol_avg = tv.rolling(20).mean().replace(0, np.nan).fillna(tv.mean())\n",
                "        df['volume_ratio'] = tv / vol_avg\n",
                "        df['volume_trend'] = (tv.rolling(10).mean() - tv.rolling(20).mean()) / (tv.rolling(20).mean() + 1e-8)\n",
                "        df['price_volume_corr'] = df['close'].pct_change().rolling(10).corr(tv.pct_change())\n",
                "    else:\n",
                "        df['volume_ratio'], df['volume_trend'], df['price_volume_corr'] = 1.0, 0.0, 0.0\n",
                "\n",
                "    # 9. SESSION CONTEXT\n",
                "    sh = df['high'].groupby(dg).cummax()\n",
                "    sl = df['low'].groupby(dg).cummin()\n",
                "    sr = (sh - sl).replace(0, np.nan).fillna(1e-8)\n",
                "    df['dist_session_high'] = (sh - df['close']) / df['atr']\n",
                "    df['dist_session_low'] = (df['close'] - sl) / df['atr']\n",
                "    df['session_range_position'] = (df['close'] - sl) / sr\n",
                "    dh = df['high'].resample('D').max()\n",
                "    dlw = df['low'].resample('D').min()\n",
                "    dr = (dh - dlw).dropna()\n",
                "    ar = dr.rolling(20, min_periods=1).mean()\n",
                "    ratio = dr / ar.replace(0, np.nan).fillna(1e-8)\n",
                "    date_idx = pd.Series(df.index.date, index=df.index)\n",
                "    df['session_range_ratio'] = date_idx.map(ratio.to_dict()).fillna(1.0).values\n",
                "\n",
                "    # 10. MULTI-TF\n",
                "    h1_ema = ta.ema(df['close'], length=48)\n",
                "    df['h1_trend'] = (h1_ema - h1_ema.shift(12)) / df['atr']\n",
                "    h1_rsi = ta.rsi(df['close'], length=56)\n",
                "    df['h1_momentum'] = (h1_rsi / 100.0) if h1_rsi is not None else 0.5\n",
                "\n",
                "    # CLEANUP\n",
                "    df.fillna(0, inplace=True)\n",
                "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
                "    for f in Settings.FEATURES:\n",
                "        if f in df.columns: df[f] = df[f].clip(-10, 10)\n",
                "    return df.iloc[250:]\n",
                "\n",
                "print('V2 feature engineering loaded.')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load & Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load CSV\n",
                "raw_df = pd.read_csv(Settings.CSV_PATH)\n",
                "raw_df['time'] = pd.to_datetime(raw_df['time'], format='mixed')\n",
                "raw_df.set_index('time', inplace=True)\n",
                "print(f'Loaded {len(raw_df)} M5 bars: {raw_df.index[0]} -> {raw_df.index[-1]}')\n",
                "\n",
                "# Resample M5 -> M15\n",
                "df = resample_ohlcv(raw_df, '15min')\n",
                "print(f'M15 bars: {len(df)}')\n",
                "\n",
                "# Compute features\n",
                "df = prepare_features(df)\n",
                "print(f'Bars after features: {len(df)}')\n",
                "\n",
                "# Extract arrays\n",
                "available_feats = [f for f in Settings.FEATURES if f in df.columns]\n",
                "print(f'Available features: {len(available_feats)}/{Settings.INPUT_DIM}')\n",
                "\n",
                "feature_data = df[available_feats].values.astype(np.float32)\n",
                "close_prices = df['close'].values.astype(np.float64)\n",
                "\n",
                "# Train/Val split (80/20)\n",
                "total = len(feature_data)\n",
                "train_end = int(total * 0.8)\n",
                "print(f'Train: {train_end} bars | Val: {total - train_end} bars')\n",
                "print(f'Train period: {df.index[0]} -> {df.index[train_end-1]}')\n",
                "print(f'Val period: {df.index[train_end]} -> {df.index[-1]}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PER (Prioritized Experience Replay)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SumTree:\n",
                "    def __init__(self, capacity):\n",
                "        self.capacity = capacity\n",
                "        self.tree = np.zeros(2 * capacity - 1)\n",
                "        self.data = np.zeros(capacity, dtype=object)\n",
                "        self.write = 0\n",
                "        self.count = 0\n",
                "\n",
                "    def _propagate(self, idx, change):\n",
                "        parent = (idx - 1) // 2\n",
                "        self.tree[parent] += change\n",
                "        if parent != 0: self._propagate(parent, change)\n",
                "\n",
                "    def _retrieve(self, idx, s):\n",
                "        left = 2 * idx + 1\n",
                "        right = left + 1\n",
                "        if left >= len(self.tree): return idx\n",
                "        return self._retrieve(left, s) if s <= self.tree[left] else self._retrieve(right, s - self.tree[left])\n",
                "\n",
                "    def total(self): return self.tree[0]\n",
                "\n",
                "    def add(self, p, data):\n",
                "        idx = self.write + self.capacity - 1\n",
                "        self.data[self.write] = data\n",
                "        self.update(idx, p)\n",
                "        self.write = (self.write + 1) % self.capacity\n",
                "        if self.count < self.capacity: self.count += 1\n",
                "\n",
                "    def update(self, idx, p):\n",
                "        change = p - self.tree[idx]\n",
                "        self.tree[idx] = p\n",
                "        self._propagate(idx, change)\n",
                "\n",
                "    def get(self, s):\n",
                "        idx = self._retrieve(0, s)\n",
                "        return (idx, self.tree[idx], self.data[idx - self.capacity + 1])\n",
                "\n",
                "\n",
                "class PERBuffer:\n",
                "    def __init__(self, capacity, alpha=0.6):\n",
                "        self.tree = SumTree(capacity)\n",
                "        self.alpha = alpha\n",
                "\n",
                "    def push(self, state, action, reward, next_state, done):\n",
                "        max_p = np.max(self.tree.tree[-self.tree.capacity:])\n",
                "        if max_p == 0: max_p = 1.0\n",
                "        self.tree.add(max_p, (state, action, reward, next_state, done))\n",
                "\n",
                "    def sample(self, batch_size, beta=0.4):\n",
                "        batch, idxs, prios = [], [], []\n",
                "        seg = self.tree.total() / batch_size\n",
                "        for i in range(batch_size):\n",
                "            s = random.uniform(seg * i, seg * (i + 1))\n",
                "            idx, p, data = self.tree.get(s)\n",
                "            if data == 0 or data is None:\n",
                "                vi = random.randint(0, self.tree.count - 1)\n",
                "                data = self.tree.data[vi]\n",
                "                idx = vi + self.tree.capacity - 1\n",
                "                p = self.tree.tree[idx]\n",
                "            prios.append(p)\n",
                "            batch.append(data)\n",
                "            idxs.append(idx)\n",
                "        sp = np.array(prios) / self.tree.total()\n",
                "        w = np.power(self.tree.count * sp, -beta)\n",
                "        w /= w.max()\n",
                "        states, actions, rewards, next_states, dones = zip(*batch)\n",
                "        return list(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
                "               list(next_states), np.array(dones, dtype=bool), idxs, np.array(w, dtype=np.float32)\n",
                "\n",
                "    def update_priorities(self, idxs, errors):\n",
                "        for idx, e in zip(idxs, errors):\n",
                "            self.tree.update(idx, (abs(e) + 1e-5) ** self.alpha)\n",
                "\n",
                "    def __len__(self): return self.tree.count\n",
                "\n",
                "print('PER buffer loaded.')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Position-Aware QNetwork"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class QNetwork(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.feature_encoder = nn.Sequential(\n",
                "            nn.Linear(Settings.INPUT_DIM, Settings.INPUT_DIM),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(Settings.INPUT_DIM, Settings.ENCODER_DIM),\n",
                "            nn.ReLU()\n",
                "        )\n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=Settings.ENCODER_DIM,\n",
                "            hidden_size=Settings.HIDDEN_DIM,\n",
                "            num_layers=Settings.NUM_LAYERS,\n",
                "            dropout=Settings.DROPOUT if Settings.NUM_LAYERS > 1 else 0,\n",
                "            batch_first=True\n",
                "        )\n",
                "        self.layer_norm = nn.LayerNorm(Settings.HIDDEN_DIM)\n",
                "        fc_in = Settings.HIDDEN_DIM + Settings.TRADE_STATE_DIM\n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Linear(fc_in, Settings.HIDDEN_DIM // 2),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(Settings.DROPOUT),\n",
                "            nn.Linear(Settings.HIDDEN_DIM // 2, Settings.OUTPUT_DIM)\n",
                "        )\n",
                "\n",
                "    def forward(self, x, trade_state=None):\n",
                "        B, S, _ = x.size()\n",
                "        enc = self.feature_encoder(x.reshape(B*S, -1)).reshape(B, S, -1)\n",
                "        out, _ = self.lstm(enc)\n",
                "        h = self.layer_norm(out[:, -1, :])\n",
                "        if trade_state is None:\n",
                "            trade_state = torch.zeros(B, Settings.TRADE_STATE_DIM, device=x.device)\n",
                "        return self.fc(torch.cat([h, trade_state], dim=1))\n",
                "\n",
                "# Test\n",
                "net = QNetwork().to(device)\n",
                "x = torch.randn(2, Settings.SEQUENCE_LENGTH, Settings.INPUT_DIM).to(device)\n",
                "ts = torch.randn(2, Settings.TRADE_STATE_DIM).to(device)\n",
                "print(f'QNetwork output: {net(x, ts).shape}')  # [2, 4]\n",
                "total_params = sum(p.numel() for p in net.parameters())\n",
                "print(f'Total parameters: {total_params:,}')\n",
                "del net, x, ts\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Trading Environment (Sequential, Position-Aware)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ACT_HOLD, ACT_BUY, ACT_SELL, ACT_CLOSE = 0, 1, 2, 3\n",
                "\n",
                "class TradingEnv:\n",
                "    def __init__(self, features, close_prices, seq_len, cost_bps=2, sf=10000.0):\n",
                "        self.features = features\n",
                "        self.close_prices = close_prices\n",
                "        self.seq_len = seq_len\n",
                "        self.cost_frac = cost_bps * 0.0001\n",
                "        self.sf = sf\n",
                "        self.reset()\n",
                "\n",
                "    def reset(self, start_idx=None):\n",
                "        self.pos = 0.0\n",
                "        self.entry_price = 0.0\n",
                "        self.bars_held = 0\n",
                "        self.step_idx = start_idx if start_idx else self.seq_len\n",
                "        self.done = False\n",
                "        return self._state()\n",
                "\n",
                "    def _state(self):\n",
                "        mkt = self.features[self.step_idx - self.seq_len:self.step_idx]\n",
                "        cp = self.close_prices[self.step_idx - 1]\n",
                "        upnl = self.pos * (cp - self.entry_price) * self.sf if self.pos != 0 and self.entry_price > 0 else 0.0\n",
                "        ts = np.array([self.pos, min(self.bars_held / 48.0, 1.0), np.clip(upnl / 100.0, -1, 1)], dtype=np.float32)\n",
                "        return mkt, ts\n",
                "\n",
                "    def step(self, action):\n",
                "        if self.done: return self._state(), 0.0, True, {}\n",
                "        cp = self.close_prices[self.step_idx - 1]\n",
                "        old_pos = self.pos\n",
                "\n",
                "        # Execute action\n",
                "        if action == ACT_BUY and self.pos <= 0:\n",
                "            self.pos, self.entry_price, self.bars_held = 1.0, cp, 0\n",
                "        elif action == ACT_SELL and self.pos >= 0:\n",
                "            self.pos, self.entry_price, self.bars_held = -1.0, cp, 0\n",
                "        elif action == ACT_CLOSE and self.pos != 0:\n",
                "            self.pos, self.entry_price, self.bars_held = 0.0, 0.0, 0\n",
                "\n",
                "        pos_changed = (self.pos != old_pos)\n",
                "        self.step_idx += 1\n",
                "\n",
                "        if self.step_idx >= len(self.close_prices):\n",
                "            self.done = True\n",
                "            r = 0.0\n",
                "            if self.pos != 0:\n",
                "                r = self.pos * (self.close_prices[-1] - self.entry_price) * self.sf\n",
                "                r -= self.cost_frac * self.sf\n",
                "            return self._state(), np.clip(r, -Settings.REWARD_CLIP, Settings.REWARD_CLIP), True, {}\n",
                "\n",
                "        np_ = self.close_prices[self.step_idx - 1]\n",
                "        reward = 0.0\n",
                "        if pos_changed:\n",
                "            reward -= self.cost_frac * self.sf * abs(self.pos - old_pos)\n",
                "            reward -= Settings.TRADE_PENALTY  # Discourage churning\n",
                "        if self.pos != 0:\n",
                "            reward += self.pos * (np_ - cp) * self.sf\n",
                "            self.bars_held += 1\n",
                "            if self.bars_held > Settings.HOLD_BONUS_MIN_BARS:\n",
                "                reward += Settings.HOLD_BONUS  # Patience bonus\n",
                "\n",
                "        reward = np.clip(reward, -Settings.REWARD_CLIP, Settings.REWARD_CLIP)\n",
                "        return self._state(), reward, False, {'pos_changed': pos_changed, 'pos': self.pos}\n",
                "\n",
                "# Test\n",
                "env = TradingEnv(feature_data[:500], close_prices[:500], Settings.SEQUENCE_LENGTH)\n",
                "s = env.reset()\n",
                "print(f'Market state: {s[0].shape}, Trade state: {s[1].shape}')\n",
                "for _ in range(10):\n",
                "    s, r, d, i = env.step(random.randint(0, 3))\n",
                "print(f'After 10 random steps: pos={env.pos}, bars_held={env.bars_held}')\n",
                "del env\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def soft_update(policy, target, tau=Settings.TAU):\n",
                "    for p, t in zip(policy.parameters(), target.parameters()):\n",
                "        t.data.copy_(tau * p.data + (1 - tau) * t.data)\n",
                "\n",
                "def train_step(policy, target, optimizer, memory, loss_fn):\n",
                "    policy.train()\n",
                "    states, actions, rewards, nstates, dones, idxs, weights = memory.sample(\n",
                "        Settings.BATCH_SIZE, Settings.PER_BETA_START)\n",
                "    mkt = torch.FloatTensor(np.array([s[0] for s in states])).to(device)\n",
                "    ts = torch.FloatTensor(np.array([s[1] for s in states])).to(device)\n",
                "    a = torch.LongTensor(actions).to(device)\n",
                "    r = torch.FloatTensor(rewards).to(device)\n",
                "    nmkt = torch.FloatTensor(np.array([s[0] for s in nstates])).to(device)\n",
                "    nts = torch.FloatTensor(np.array([s[1] for s in nstates])).to(device)\n",
                "    d_t = torch.FloatTensor(dones.astype(np.float32)).to(device)\n",
                "    w_t = torch.FloatTensor(weights).to(device)\n",
                "\n",
                "    with torch.enable_grad():\n",
                "        q = policy(mkt, ts).gather(1, a.unsqueeze(1)).squeeze(1)\n",
                "        with torch.no_grad():\n",
                "            best_a = policy(nmkt, nts).argmax(dim=1, keepdim=True)\n",
                "            nq = target(nmkt, nts).gather(1, best_a).squeeze(1)\n",
                "            tgt = r + Settings.GAMMA * nq * (1 - d_t)\n",
                "        loss = (loss_fn(q, tgt) * w_t).mean()\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "    torch.nn.utils.clip_grad_norm_(policy.parameters(), 1.0)\n",
                "    optimizer.step()\n",
                "    td_err = (q - tgt).abs().detach().cpu().numpy() + 1e-6\n",
                "    memory.update_priorities(idxs, td_err)\n",
                "    return loss.item()\n",
                "\n",
                "def validate(policy, features, prices, sf):\n",
                "    policy.eval()\n",
                "    env = TradingEnv(features, prices, Settings.SEQUENCE_LENGTH, sf=sf)\n",
                "    mkt, ts = env.reset()\n",
                "    daily, bar_r, bar_c = [], 0.0, 0\n",
                "    trades = 0\n",
                "    with torch.no_grad():\n",
                "        while not env.done:\n",
                "            mt = torch.FloatTensor(mkt).unsqueeze(0).to(device)\n",
                "            tt = torch.FloatTensor(ts).unsqueeze(0).to(device)\n",
                "            a = policy(mt, tt).argmax(dim=1).item()\n",
                "            (mkt, ts), r, done, info = env.step(a)\n",
                "            if info.get('pos_changed'): trades += 1\n",
                "            bar_r += r\n",
                "            bar_c += 1\n",
                "            if bar_c >= 96:  # ~1 day of M15\n",
                "                daily.append(bar_r)\n",
                "                bar_r, bar_c = 0.0, 0\n",
                "            if done:\n",
                "                if bar_c > 0: daily.append(bar_r)\n",
                "                break\n",
                "    policy.train()\n",
                "    if len(daily) < 5: return 0.0, 0.0, trades\n",
                "    daily = np.array(daily)\n",
                "    sharpe = (daily.mean() / (daily.std() + 1e-8)) * np.sqrt(252)\n",
                "    return sharpe, daily.sum(), trades\n",
                "\n",
                "print('Training functions loaded.')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize\n",
                "policy_net = QNetwork().to(device)\n",
                "target_net = copy.deepcopy(policy_net).to(device)\n",
                "target_net.eval()\n",
                "optimizer = optim.Adam(policy_net.parameters(), lr=Settings.LEARNING_RATE, weight_decay=1e-4)\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.5)\n",
                "loss_fn = nn.SmoothL1Loss(reduction='none')\n",
                "memory = PERBuffer(Settings.MEMORY_CAPACITY, Settings.PER_ALPHA)\n",
                "\n",
                "SF = Settings.SCALING_FACTOR\n",
                "epsilon = Settings.EPSILON_START\n",
                "total_steps = 0\n",
                "best_sharpe = -np.inf\n",
                "patience = 0\n",
                "train_feats = feature_data[:train_end]\n",
                "train_prices = close_prices[:train_end]\n",
                "max_start = train_end - Settings.SEQUENCE_LENGTH - Settings.EPISODE_LENGTH - 1\n",
                "history = {'epoch': [], 'reward': [], 'trades': [], 'val_sharpe': [], 'val_return': [], 'epsilon': [], 'loss': []}\n",
                "\n",
                "for epoch in range(1, Settings.EPOCHS + 1):\n",
                "    policy_net.train()\n",
                "    ep_reward, ep_trades, losses = 0.0, 0, []\n",
                "    pbar = tqdm(range(Settings.EPISODES_PER_EPOCH), desc=f'Epoch {epoch}/{Settings.EPOCHS}', ncols=110)\n",
                "\n",
                "    for ep_i in pbar:\n",
                "        # Random start point for this mini-rollout\n",
                "        start = random.randint(Settings.SEQUENCE_LENGTH, max_start)\n",
                "        env = TradingEnv(train_feats, train_prices, Settings.SEQUENCE_LENGTH,\n",
                "                         Settings.TRANSACTION_COST_BPS, SF)\n",
                "        mkt, ts = env.reset(start_idx=start)\n",
                "\n",
                "        for step in range(Settings.EPISODE_LENGTH):\n",
                "            # Skip forward pass when taking random action (optimization #3)\n",
                "            if random.random() < epsilon:\n",
                "                action = random.randint(0, Settings.OUTPUT_DIM - 1)\n",
                "            else:\n",
                "                mt = torch.FloatTensor(mkt).unsqueeze(0).to(device)\n",
                "                tt = torch.FloatTensor(ts).unsqueeze(0).to(device)\n",
                "                with torch.no_grad():\n",
                "                    action = policy_net(mt, tt).argmax(dim=1).item()\n",
                "\n",
                "            (nmkt, nts), reward, done, info = env.step(action)\n",
                "            if info.get('pos_changed'): ep_trades += 1\n",
                "\n",
                "            memory.push((mkt.copy(), ts.copy()), action, reward, (nmkt.copy(), nts.copy()), done)\n",
                "            mkt, ts = nmkt, nts\n",
                "            ep_reward += reward\n",
                "            total_steps += 1\n",
                "\n",
                "            epsilon = max(Settings.EPSILON_MIN, 1.0 - total_steps / Settings.EPSILON_DECAY_STEPS)\n",
                "\n",
                "            if len(memory) >= Settings.BATCH_SIZE and total_steps % 8 == 0:\n",
                "                l = train_step(policy_net, target_net, optimizer, memory, loss_fn)\n",
                "                losses.append(l)\n",
                "\n",
                "            if total_steps % Settings.TARGET_UPDATE_FREQ == 0:\n",
                "                soft_update(policy_net, target_net)\n",
                "\n",
                "            if done: break\n",
                "\n",
                "        if ep_i % 20 == 0:\n",
                "            al = np.mean(losses[-200:]) if losses else 0\n",
                "            pbar.set_postfix({'R': f'{ep_reward:.0f}', 'T': ep_trades, 'e': f'{epsilon:.3f}', 'L': f'{al:.4f}'})\n",
                "\n",
                "    pbar.close()\n",
                "    avg_loss = np.mean(losses) if losses else 0\n",
                "\n",
                "    # Validate\n",
                "    vs, vr, vt = validate(policy_net, feature_data[train_end:], close_prices[train_end:], SF)\n",
                "    scheduler.step(vs)\n",
                "\n",
                "    history['epoch'].append(epoch)\n",
                "    history['reward'].append(ep_reward)\n",
                "    history['trades'].append(ep_trades)\n",
                "    history['val_sharpe'].append(vs)\n",
                "    history['val_return'].append(vr)\n",
                "    history['epsilon'].append(epsilon)\n",
                "    history['loss'].append(avg_loss)\n",
                "\n",
                "    print(f'Epoch {epoch}: R={ep_reward:.0f} T={ep_trades} eps={epsilon:.4f} L={avg_loss:.4f} | '\n",
                "          f'Val Sharpe={vs:.3f} Val Return={vr:.1f} Val Trades={vt}')\n",
                "\n",
                "    if vs > best_sharpe:\n",
                "        best_sharpe = vs\n",
                "        patience = 0\n",
                "        torch.save(policy_net.state_dict(), f'/content/best_{Settings.PAIR}.pt')\n",
                "        print(f'  ** New best! Saved. **')\n",
                "    else:\n",
                "        patience += 1\n",
                "        if patience >= Settings.EARLY_STOP_PATIENCE:\n",
                "            print(f'Early stopping at epoch {epoch}')\n",
                "            break\n",
                "\n",
                "    gc.collect()\n",
                "    if device.type == 'cuda': torch.cuda.empty_cache()\n",
                "\n",
                "print(f'\\nTraining complete. Best val Sharpe: {best_sharpe:.3f}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "\n",
                "axes[0, 0].plot(history['epoch'], history['reward'])\n",
                "axes[0, 0].set_title('Episode Reward'); axes[0, 0].set_xlabel('Epoch')\n",
                "\n",
                "axes[0, 1].plot(history['epoch'], history['trades'])\n",
                "axes[0, 1].set_title('Trades per Epoch'); axes[0, 1].set_xlabel('Epoch')\n",
                "\n",
                "axes[0, 2].plot(history['epoch'], history['epsilon'])\n",
                "axes[0, 2].set_title('Epsilon'); axes[0, 2].set_xlabel('Epoch')\n",
                "\n",
                "axes[1, 0].plot(history['epoch'], history['val_sharpe'])\n",
                "axes[1, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
                "axes[1, 0].set_title('Validation Sharpe'); axes[1, 0].set_xlabel('Epoch')\n",
                "\n",
                "axes[1, 1].plot(history['epoch'], history['val_return'])\n",
                "axes[1, 1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
                "axes[1, 1].set_title('Validation Return'); axes[1, 1].set_xlabel('Epoch')\n",
                "\n",
                "axes[1, 2].plot(history['epoch'], history['loss'])\n",
                "axes[1, 2].set_title('Avg Loss'); axes[1, 2].set_xlabel('Epoch')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/training_curves.png', dpi=150)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Download Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "model_path = f'/content/best_{Settings.PAIR}.pt'\n",
                "if os.path.exists(model_path):\n",
                "    files.download(model_path)\n",
                "    print(f'Model downloaded: {model_path}')\n",
                "else:\n",
                "    print('No model saved (training may not have improved).')\n"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
