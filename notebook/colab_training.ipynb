{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f4a586eb",
            "metadata": {},
            "source": [
                "# Deep Multi-Pair Forex Trading System - Colab Training\n",
                "\n",
                "**Phases Implemented:**\n",
                "- Phase 11 & 12: Godlike Scalper + Machine Gunner\n",
                "- Phase 13: ADX Filter + Hybrid Reward\n",
                "- Phase 14: Mid-Price Target (Noise Reduction)\n",
                "- Phase 15 & 17: Rich Factor Expansion (Mined 50 Features)\n",
                "- Phase 16 & 18: PER (Priority Tuned to Alpha=0.7)\n",
                "\n",
                "**Data Location:** `/content/drive/MyDrive/data/{symbol}.csv`\n",
                "\n",
                "### \u26a1 enable GPU\n",
                "To speed up training, ensure you really are using a GPU Runtime:\n",
                "1. In the menu, go to **Runtime** > **Change runtime type**.\n",
                "2. Select **T4 GPU** (or better) under Hardware accelerator.\n",
                "3. Click **Save**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d493a57",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gpu_check",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify GPU\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"\u2705 GPU Available: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f GPU NOT Detected! Please enable it in Runtime > Change runtime type.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9953daff",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install pandas_ta"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22c2809d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import pandas as pd\n",
                "import pandas_ta as ta\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "import os\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import random\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ccba8890",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIGURATION ---\n",
                "class Settings:\n",
                "    # --- TRADING PAIRS & PROFILES ---\n",
                "    # OPTIMIZATION: Zero Commission & Balanced Scaling\n",
                "    PAIR_CONFIGS = {\n",
                "        'XAUUSD': {\n",
                "            'spread': 0.20,\n",
                "            'commission': 0.0,       # Zero Comm\n",
                "            'scaling_factor': 5.0,   # Increased High Scaling for Gold (Difficulty Balance)\n",
                "            'contract_size': 100\n",
                "        },\n",
                "        'EURUSD': {\n",
                "            'spread': 0.0001,\n",
                "            'commission': 0.0,       # Zero Comm\n",
                "            'scaling_factor': 10000.0,\n",
                "            'contract_size': 100000\n",
                "        },\n",
                "        'GBPUSD': {\n",
                "            'spread': 0.0002,\n",
                "            'commission': 0.0,       # Zero Comm\n",
                "            'scaling_factor': 10000.0,\n",
                "            'contract_size': 100000\n",
                "        }\n",
                "    }\n",
                "    PAIRS = list(PAIR_CONFIGS.keys())\n",
                "    \n",
                "    # Core\n",
                "    SEQUENCE_LENGTH = 12 # Scalper: React to last hour only\n",
                "    \n",
                "    # RICH FACTORS (Mined Phase 17 - Top 50) + ADX (Filter)\n",
                "    FEATURES = [\n",
                "        'spread_close_mid_price', 'rel_close_mid_price', 'spread_low_close', 'rel_low_close', \n",
                "        'spread_high_close', 'rel_high_close', 'diff_close_close_lag1', 'rel_open_close', \n",
                "        'spread_open_close', 'ratio_close_lag1', 'diff_close_lag1', 'diff_close_mid_price_lag1', \n",
                "        'diff_close_low_lag1', 'diff_close_high_lag1', 'ratio_close_lag2', 'diff_close_close_lag2', \n",
                "        'diff_close_lag2', 'diff_close_mid_price_lag2', 'diff_close_open_lag1', 'diff_close_open_lag2', \n",
                "        'spread_open_high', 'diff_low_close_lag1', 'spread_open_mid_price', 'ratio_close_lag3', \n",
                "        'diff_close_low_lag2', 'rel_open_low', 'diff_close_high_lag2', 'diff_close_close_lag3', \n",
                "        'rel_open_mid_price', 'spread_open_low', 'rel_open_high', 'diff_mid_price_close_lag1', \n",
                "        'ratio_close_lag5', 'diff_close_lag3', 'diff_close_low_lag3', 'diff_close_open_lag3', \n",
                "        'ratio_low_lag1', 'diff_close_high_lag3', 'rel_low_mid_price', 'diff_high_close_lag1', \n",
                "        'spread_high_low', 'diff_close_high_lag5', 'rel_high_low', 'diff_close_mid_price_lag3', \n",
                "        'spread_high_mid_price', 'rel_high_mid_price', 'spread_low_mid_price', 'diff_low_low_lag1', \n",
                "        'diff_mid_price_mid_price_lag1', 'diff_mid_price_lag1',\n",
                "        'adx' # Start index -1 for Filter\n",
                "    ]\n",
                "    \n",
                "    INPUT_DIM = len(FEATURES)\n",
                "    HIDDEN_DIM = 128\n",
                "    NUM_LAYERS = 2\n",
                "    DROPOUT = 0.2\n",
                "    OUTPUT_DIM = 3 \n",
                "\n",
                "    # Training\n",
                "    EPOCHS = 50 \n",
                "    BATCH_SIZE = 64\n",
                "    LEARNING_RATE = 0.001 # Aggressive Learning for Binary Scalper\n",
                "    GAMMA = 0.85  # Scalper: Greedy for immediate reward\n",
                "    EPSILON_START = 1.0\n",
                "    EPSILON_DECAY = 0.92\n",
                "    EPSILON_MIN = 0.01\n",
                "    \n",
                "    # PER (Prioritized Experience Replay)\n",
                "    # PLAN 3 Tuned Value\n",
                "    PER_ALPHA = 0.7\n",
                "    PER_BETA_START = 0.4\n",
                "    \n",
                "    # Data\n",
                "    TRAIN_SPLIT_INDEX = 420000\n",
                "    ATR_PERIOD = 14"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b96fb512",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- MODEL (Brain) ---\n",
                "class QNetwork(nn.Module):\n",
                "    def __init__(self, input_dim=Settings.INPUT_DIM, \n",
                "                 hidden_dim=Settings.HIDDEN_DIM, \n",
                "                 num_layers=Settings.NUM_LAYERS, \n",
                "                 dropout=Settings.DROPOUT, \n",
                "                 output_dim=Settings.OUTPUT_DIM):\n",
                "        super(QNetwork, self).__init__()\n",
                "        \n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=input_dim,\n",
                "            hidden_size=hidden_dim,\n",
                "            num_layers=num_layers,\n",
                "            dropout=dropout if num_layers > 1 else 0,\n",
                "            batch_first=True\n",
                "        )\n",
                "        \n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(hidden_dim // 2, output_dim)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        lstm_out, _ = self.lstm(x)\n",
                "        last_step_out = lstm_out[:, -1, :]\n",
                "        q_values = self.fc(last_step_out)\n",
                "        return q_values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "per_memory",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- PRIORITIZED EXPERIENCE REPLAY (PER) ---\n",
                "class SumTree:\n",
                "    def __init__(self, capacity):\n",
                "        self.capacity = capacity\n",
                "        self.tree = np.zeros(2 * capacity - 1)\n",
                "        self.data = np.zeros(capacity, dtype=object)\n",
                "        self.write = 0\n",
                "        self.count = 0\n",
                "\n",
                "    def _propagate(self, idx, change):\n",
                "        parent = (idx - 1) // 2\n",
                "        self.tree[parent] += change\n",
                "        if parent != 0:\n",
                "            self._propagate(parent, change)\n",
                "\n",
                "    def _retrieve(self, idx, s):\n",
                "        left = 2 * idx + 1\n",
                "        right = left + 1\n",
                "        if left >= len(self.tree):\n",
                "            return idx\n",
                "        if s <= self.tree[left]:\n",
                "            return self._retrieve(left, s)\n",
                "        else:\n",
                "            return self._retrieve(right, s - self.tree[left])\n",
                "\n",
                "    def total(self):\n",
                "        return self.tree[0]\n",
                "\n",
                "    def add(self, p, data):\n",
                "        idx = self.write + self.capacity - 1\n",
                "        self.data[self.write] = data\n",
                "        self.update(idx, p)\n",
                "        self.write += 1\n",
                "        if self.write >= self.capacity:\n",
                "            self.write = 0   \n",
                "        if self.count < self.capacity:\n",
                "            self.count += 1\n",
                "\n",
                "    def update(self, idx, p):\n",
                "        change = p - self.tree[idx]\n",
                "        self.tree[idx] = p\n",
                "        self._propagate(idx, change)\n",
                "\n",
                "    def get(self, s):\n",
                "        idx = self._retrieve(0, s)\n",
                "        dataIdx = idx - self.capacity + 1\n",
                "        return (idx, self.tree[idx], self.data[dataIdx])\n",
                "\n",
                "class PrioritizedReplayBuffer:\n",
                "    def __init__(self, capacity=10000, alpha=0.7):\n",
                "        self.tree = SumTree(capacity)\n",
                "        self.alpha = alpha \n",
                "        self.capacity = capacity\n",
                "        \n",
                "    def push(self, state, action, reward, next_state, done):\n",
                "        max_prio = np.max(self.tree.tree[-self.tree.capacity:]) \n",
                "        if max_prio == 0:\n",
                "            max_prio = 1.0\n",
                "        data = (state, action, reward, next_state, done)\n",
                "        self.tree.add(max_prio, data)\n",
                "\n",
                "    def sample(self, batch_size, beta=0.4):\n",
                "        batch = []\n",
                "        idxs = []\n",
                "        segment = self.tree.total() / batch_size\n",
                "        priorities = []\n",
                "\n",
                "        for i in range(batch_size):\n",
                "            a = segment * i\n",
                "            b = segment * (i + 1)\n",
                "            s = random.uniform(a, b)\n",
                "            (idx, p, data) = self.tree.get(s)\n",
                "            if data == 0 or data is None:\n",
                "                 valid_idx = random.randint(0, self.tree.count - 1)\n",
                "                 data = self.tree.data[valid_idx]\n",
                "                 idx = valid_idx + self.capacity - 1\n",
                "                 p = self.tree.tree[idx]\n",
                "            priorities.append(p)\n",
                "            batch.append(data)\n",
                "            idxs.append(idx)\n",
                "\n",
                "        sampling_probabilities = np.array(priorities) / self.tree.total()\n",
                "        is_weights = np.power(self.tree.count * sampling_probabilities, -beta)\n",
                "        is_weights /= is_weights.max()\n",
                "        \n",
                "        states, actions, rewards, next_states, dones = zip(*batch)\n",
                "        return (\n",
                "            np.array(states), \n",
                "            np.array(actions), \n",
                "            np.array(rewards, dtype=np.float32), \n",
                "            np.array(next_states), \n",
                "            np.array(dones, dtype=bool),\n",
                "            idxs,\n",
                "            np.array(is_weights, dtype=np.float32)\n",
                "        )\n",
                "\n",
                "    def update_priorities(self, idxs, errors):\n",
                "        for idx, error in zip(idxs, errors):\n",
                "            p = (abs(error) + 1e-5) ** self.alpha\n",
                "            self.tree.update(idx, p)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b9a79635",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- DYNAMIC FEATURE GENERATION ---\n",
                "def prepare_features(df):\n",
                "    if df.empty:\n",
                "        return df\n",
                "    df = df.copy()\n",
                "\n",
                "    # --- MID-PRICE (Noise Reduction) ---\n",
                "    df['mid_price'] = (df['high'] + df['low']) / 2.0\n",
                "\n",
                "    # --- FILTER INDICATORS ---\n",
                "    bb = ta.bbands(df['mid_price'], length=20, std=2)\n",
                "    bb.columns = ['BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'BBB_20_2.0', 'BBP_20_2.0']\n",
                "    df = pd.concat([df, bb], axis=1)\n",
                "\n",
                "    adx_df = ta.adx(df['high'], df['low'], df['close'], length=14)\n",
                "    df['adx'] = adx_df['ADX_14'] / 100.0\n",
                "    \n",
                "    # --- DYNAMIC FEATURE GENERATION ---\n",
                "    for feature in Settings.FEATURES:\n",
                "        if feature in df.columns:\n",
                "            continue\n",
                "        try:\n",
                "            parts = feature.split('_')\n",
                "            type_ = parts[0]\n",
                "            \n",
                "            # REL & SPREAD (Already Robust)\n",
                "            if type_ == 'rel':\n",
                "                rest = feature.replace('rel_', '')\n",
                "                known_cols = ['open', 'high', 'low', 'close', 'mid_price']\n",
                "                c1, c2 = None, None\n",
                "                for k in known_cols:\n",
                "                    if rest.startswith(k + '_'):\n",
                "                        c1 = k\n",
                "                        c2 = rest.replace(k + '_', '')\n",
                "                        break\n",
                "                if c1 and c2:\n",
                "                    df[feature] = df[c1] / df[c2]\n",
                "            elif type_ == 'spread':\n",
                "                rest = feature.replace('spread_', '')\n",
                "                known_cols = ['open', 'high', 'low', 'close', 'mid_price']\n",
                "                c1, c2 = None, None\n",
                "                for k in known_cols:\n",
                "                    if rest.startswith(k + '_'):\n",
                "                        c1 = k\n",
                "                        c2 = rest.replace(k + '_', '')\n",
                "                        break\n",
                "                if c1 and c2:\n",
                "                    df[feature] = df[c1] - df[c2]\n",
                "            \n",
                "            # RATIO & DIFF (Robust Unified Logic)\n",
                "            elif type_ == 'ratio':\n",
                "                rest = feature.replace('ratio_', '')\n",
                "                if '_lag' in rest:\n",
                "                    base, lag_str = rest.split('_lag')\n",
                "                    lag = int(lag_str)\n",
                "                    \n",
                "                    known_cols = ['open', 'high', 'low', 'close', 'mid_price']\n",
                "                    c1, c2 = None, None\n",
                "                    \n",
                "                    if base in known_cols:\n",
                "                        df[feature] = df[base] / df[base].shift(lag)\n",
                "                    else:\n",
                "                        for k in known_cols:\n",
                "                            if base.startswith(k + '_'):\n",
                "                                c1 = k\n",
                "                                c2 = base.replace(k + '_', '')\n",
                "                                break\n",
                "                        if c1 and c2:\n",
                "                            df[feature] = df[c1] / df[c2].shift(lag)\n",
                "                            \n",
                "            elif type_ == 'diff':\n",
                "                 rest = feature.replace('diff_', '')\n",
                "                 if '_lag' in rest:\n",
                "                    base, lag_str = rest.split('_lag')\n",
                "                    lag = int(lag_str)\n",
                "                    \n",
                "                    known_cols = ['open', 'high', 'low', 'close', 'mid_price']\n",
                "                    c1, c2 = None, None\n",
                "                    \n",
                "                    if base in known_cols:\n",
                "                         df[feature] = df[base] - df[base].shift(lag)\n",
                "                    else:\n",
                "                         for k in known_cols:\n",
                "                            if base.startswith(k + '_'):\n",
                "                                c1 = k\n",
                "                                c2 = base.replace(k + '_', '')\n",
                "                                break\n",
                "                            \n",
                "                         if c1 and c2:\n",
                "                            df[feature] = df[c1] - df[c2].shift(lag)\n",
                "        except:\n",
                "            pass\n",
                "\n",
                "    df.fillna(0, inplace=True)\n",
                "    df = df.iloc[50:] \n",
                "    return df\n",
                "\n",
                "class TradingDataset(Dataset):\n",
                "    def __init__(self, feature_data, close_prices, seq_len):\n",
                "        self.feature_data = feature_data\n",
                "        self.close_prices = close_prices\n",
                "        self.seq_len = seq_len\n",
                "        self.valid_indices = range(seq_len, len(feature_data) - 1)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.valid_indices)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        i = self.valid_indices[idx]\n",
                "        state_window = self.feature_data[i - self.seq_len : i]\n",
                "        next_state_window = self.feature_data[i - self.seq_len + 1 : i + 1]\n",
                "        curr_price = self.close_prices[i-1]\n",
                "        next_price = self.close_prices[i]\n",
                "        return {\n",
                "            'state': torch.FloatTensor(state_window),\n",
                "            'next_state': torch.FloatTensor(next_state_window),\n",
                "            'curr_price': torch.tensor(curr_price, dtype=torch.float32),\n",
                "            'next_price': torch.tensor(next_price, dtype=torch.float32)\n",
                "        }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6394cd99",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- TRAINING ENGINE (PER EQUIPPED) ---\n",
                "def train_model(symbol, csv_path):\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    print(f\"Training {symbol} on {device}...\")\n",
                "    \n",
                "    profile = Settings.PAIR_CONFIGS.get(symbol, Settings.PAIR_CONFIGS['XAUUSD'])\n",
                "    SCALING_FACTOR = profile['scaling_factor']\n",
                "    SPREAD = profile['spread']\n",
                "    COMMISSION = profile['commission']\n",
                "    \n",
                "    # Load Data\n",
                "    df = pd.read_csv(csv_path, parse_dates=['time'], index_col='time')\n",
                "    df = prepare_features(df)\n",
                "    \n",
                "    feature_data = df[Settings.FEATURES].values\n",
                "    close_prices = df['mid_price'].values\n",
                "    \n",
                "    dataset = TradingDataset(feature_data, close_prices, Settings.SEQUENCE_LENGTH)\n",
                "    \n",
                "    # --- POPULATE PER MEMORY ---\n",
                "    memory_capacity = len(dataset)\n",
                "    memory = PrioritizedReplayBuffer(capacity=memory_capacity, alpha=Settings.PER_ALPHA)\n",
                "    \n",
                "    print(f\"Populating Replay Buffer with {memory_capacity} transitions...\")\n",
                "    temp_loader = DataLoader(dataset, batch_size=4096, shuffle=False)\n",
                "    \n",
                "    for batch in tqdm(temp_loader):\n",
                "        states = batch['state'].numpy()\n",
                "        next_states = batch['next_state'].numpy()\n",
                "        curr_prices = batch['curr_price'].numpy()\n",
                "        next_prices = batch['next_price'].numpy()\n",
                "        \n",
                "        # HACK: Store transition details in buffer as 'data' tuple\n",
                "        for i in range(len(states)):\n",
                "            memory.push(states[i], next_states[i], curr_prices[i], next_prices[i], False)\n",
                "    \n",
                "    policy_net = QNetwork().to(device)\n",
                "    optimizer = optim.Adam(policy_net.parameters(), lr=Settings.LEARNING_RATE)\n",
                "    loss_fn = nn.MSELoss(reduction='none') # Important for IS weights\n",
                "    \n",
                "    epsilon = Settings.EPSILON_START\n",
                "    loss_history = []\n",
                "    \n",
                "    steps_per_epoch = len(dataset) // Settings.BATCH_SIZE\n",
                "    \n",
                "    for epoch in range(Settings.EPOCHS):\n",
                "        total_loss = 0\n",
                "        beta = Settings.PER_BETA_START + (1.0 - Settings.PER_BETA_START) * (epoch / Settings.EPOCHS)\n",
                "        \n",
                "        pbar = tqdm(range(steps_per_epoch), desc=f\"Epoch {epoch+1}/{Settings.EPOCHS}\")\n",
                "        \n",
                "        for _ in pbar:\n",
                "            # SAMPLE FROM PER\n",
                "            # Unpack hack: actions=next_states, rewards=curr_prices, next_states=next_prices\n",
                "            states, next_states_hack, curr_prices_hack, next_prices_hack, _, idxs, is_weights = memory.sample(Settings.BATCH_SIZE, beta)\n",
                "            \n",
                "            state_tensor = torch.FloatTensor(states).to(device)\n",
                "            next_state_tensor = torch.FloatTensor(next_states_hack).to(device)\n",
                "            curr_price = torch.FloatTensor(curr_prices_hack).to(device)\n",
                "            next_price = torch.FloatTensor(next_prices_hack).to(device)\n",
                "            weights_tensor = torch.FloatTensor(is_weights).to(device)\n",
                "            \n",
                "            batch_size = state_tensor.size(0)\n",
                "            \n",
                "            # Epsilon Greedy\n",
                "            if random.random() < epsilon:\n",
                "                action_tensor = torch.randint(0, Settings.OUTPUT_DIM, (batch_size,), device=device)\n",
                "            else:\n",
                "                with torch.no_grad():\n",
                "                    q_values = policy_net(state_tensor)\n",
                "                    action_tensor = torch.argmax(q_values, dim=1)\n",
                "            \n",
                "            # Reward Calculation\n",
                "            price_diff = next_price - curr_price\n",
                "            norm_pnl = price_diff * SCALING_FACTOR\n",
                "            total_cost = (SPREAD + COMMISSION) * SCALING_FACTOR\n",
                "            base_penalty = -0.1\n",
                "            reward_tensor = torch.full((batch_size,), base_penalty, device=device)\n",
                "            \n",
                "            is_buy = (action_tensor == 1)\n",
                "            is_sell = (action_tensor == 2)\n",
                "            \n",
                "            reward_tensor[is_buy] = torch.tanh(norm_pnl - total_cost)[is_buy]\n",
                "            reward_tensor[is_sell] = torch.tanh(-norm_pnl - total_cost)[is_sell]\n",
                "            \n",
                "            # Update\n",
                "            current_q = policy_net(state_tensor).gather(1, action_tensor.unsqueeze(1)).squeeze(1)\n",
                "            with torch.no_grad():\n",
                "                next_q = policy_net(next_state_tensor).max(1)[0]\n",
                "                target_q = reward_tensor + (Settings.GAMMA * next_q)\n",
                "                \n",
                "            loss_element = loss_fn(current_q, target_q)\n",
                "            loss = (loss_element * weights_tensor).mean()\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            # Update Priorities\n",
                "            td_errors = torch.abs(target_q - current_q).detach().cpu().numpy()\n",
                "            memory.update_priorities(idxs, td_errors)\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            \n",
                "        if epsilon > Settings.EPSILON_MIN:\n",
                "            epsilon *= Settings.EPSILON_DECAY\n",
                "            \n",
                "        avg_loss = total_loss / steps_per_epoch\n",
                "        loss_history.append(avg_loss)\n",
                "        print(f\"Avg Loss: {avg_loss:.6f}, Epsilon: {epsilon:.4f}\")\n",
                "        \n",
                "    drive_save_path = os.path.join(os.path.dirname(csv_path), f\"{symbol}_brain.pth\")\n",
                "    torch.save(policy_net.state_dict(), drive_save_path)\n",
                "    print(f\"Model Saved to {drive_save_path}!\")\n",
                "    \n",
                "    plt.plot(loss_history)\n",
                "    plt.title(f\"Training Loss - {symbol}\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ca7fc7cf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- EXECUTION ---\n",
                "drive_data_path = \"/content/drive/MyDrive/data\"\n",
                "\n",
                "# \u26a1 SELECT PAIRS TO TRAIN HERE:\n",
                "pairs = ['EURUSD'] # Change to ['XAUUSD'] or Settings.PAIRS for all\n",
                "\n",
                "print(f\"Training Pairs: {pairs}\")\n",
                "\n",
                "for symbol in pairs:\n",
                "    csv_path = os.path.join(drive_data_path, f\"{symbol}.csv\")\n",
                "    if os.path.exists(csv_path):\n",
                "        print(f\"Found data for {symbol} at: {csv_path}\")\n",
                "        train_model(symbol, csv_path)\n",
                "    else:\n",
                "        print(f\"Data for {symbol} not found. Skipping.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "backtest_engine",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- BACKTEST ENGINE (Colab Version - Optimized) ---\n",
                "\n",
                "def colab_backtest(symbol, csv_path):\n",
                "    print(f\"\\n--- Starting Backtest for {symbol} ---\")\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    \n",
                "    model_path = os.path.join(os.path.dirname(csv_path), f\"{symbol}_brain.pth\")\n",
                "    \n",
                "    if not os.path.exists(model_path):\n",
                "        print(f\"Model {model_path} not found. Please train first.\")\n",
                "        return\n",
                "\n",
                "    policy_net = QNetwork().to(device)\n",
                "    try:\n",
                "        policy_net.load_state_dict(torch.load(model_path, map_location=device))\n",
                "    except RuntimeError as e:\n",
                "        print(f\"\\n!!! MODEL ARCHITECTURE MISMATCH !!!\")\n",
                "        print(f\"Error: {e}\")\n",
                "        print(f\"You need to RETRAIN the model because FEATURES have changed.\")\n",
                "        return\n",
                "        \n",
                "    policy_net.eval()\n",
                "    print(\"Model loaded.\")\n",
                "    \n",
                "    df = pd.read_csv(csv_path, parse_dates=['time'], index_col='time')\n",
                "    test_start_idx = Settings.TRAIN_SPLIT_INDEX \n",
                "    if len(df) < test_start_idx + 100:\n",
                "        print(f\"Not enough data for backtest. Total: {len(df)}, Needed: >{test_start_idx}\")\n",
                "        return\n",
                "        \n",
                "    print(f\"Backtesting on rows {test_start_idx} to {len(df)}...\")\n",
                "    \n",
                "    df = prepare_features(df)\n",
                "    \n",
                "    df_test = df.iloc[test_start_idx:].copy()\n",
                "    \n",
                "    feature_data = df_test[Settings.FEATURES].values\n",
                "    opens = df_test['open'].values\n",
                "    highs = df_test['high'].values\n",
                "    lows = df_test['low'].values\n",
                "    closes = df_test['close'].values\n",
                "    times = df_test.index\n",
                "    from pandas_ta import atr\n",
                "    # Re-calculate ATR here to be safe for Stop Loss\n",
                "    _atr = ta.atr(df_test['high'], df_test['low'], df_test['close'], length=14)\n",
                "    _atr.fillna(0, inplace=True)\n",
                "    atrs = _atr.values\n",
                "\n",
                "    balance = 10000.0\n",
                "    equity_curve = [balance]\n",
                "    position = 0 \n",
                "    entry_price = 0.0\n",
                "    stop_loss = 0.0\n",
                "    \n",
                "    contract_size = 100\n",
                "    spread_cost = 0.20\n",
                "    txn_cost = 0.0\n",
                "    lot_size = 0.01\n",
                "    \n",
                "    if symbol in Settings.PAIR_CONFIGS:\n",
                "         profile = Settings.PAIR_CONFIGS[symbol]\n",
                "         contract_size = profile['contract_size']\n",
                "         spread_cost = profile['spread'] * contract_size * lot_size\n",
                "         txn_cost = profile['commission'] * contract_size * lot_size\n",
                "    \n",
                "    trades = []\n",
                "    \n",
                "    for t in tqdm(range(Settings.SEQUENCE_LENGTH, len(df_test) - 1)):\n",
                "        state_tensor = torch.FloatTensor(feature_data[t - Settings.SEQUENCE_LENGTH : t]).unsqueeze(0).to(device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            q = policy_net(state_tensor)\n",
                "            action = torch.argmax(q, dim=1).item()\n",
                "            \n",
                "            if action != 0: \n",
                "                 # --- FILTERS ---\n",
                "                 current_time = times[t]\n",
                "                 \n",
                "                 # 1. ADX FILTER (Deep Market Avoidance)\n",
                "                 current_adx = state_tensor[0, -1, -1].item() * 100.0 \n",
                "                 if current_adx < 25:\n",
                "                     action = 0 \n",
                "                 \n",
                "                 # 2. BOLLINGER SQUEEZE FILTER\n",
                "                 prev_time = times[t-1]\n",
                "                 try:\n",
                "                     bb_u = df_test.loc[prev_time, 'BBU_20_2.0']\n",
                "                     bb_l = df_test.loc[prev_time, 'BBL_20_2.0']\n",
                "                     prev_close = df_test.loc[prev_time, 'close']\n",
                "                         \n",
                "                     width = bb_u - bb_l\n",
                "                     vol_pct = width / prev_close\n",
                "                     if vol_pct < 0.0005:\n",
                "                          action = 0\n",
                "                 except KeyError:\n",
                "                     pass\n",
                "            \n",
                "        # Execution\n",
                "        next_open = opens[t]\n",
                "        next_high = highs[t]\n",
                "        next_low = lows[t]\n",
                "        next_time = times[t]\n",
                "        atr = atrs[t-1] \n",
                "        \n",
                "        trade_closed = False\n",
                "        exit_price = 0.0\n",
                "        \n",
                "        if position != 0:\n",
                "            if next_time.hour >= 20 and next_time.minute == 0:\n",
                "                exit_price = next_open\n",
                "                trade_closed = True\n",
                "            elif position == 1:\n",
                "                 if next_low <= stop_loss:\n",
                "                      exit_price = stop_loss\n",
                "                      trade_closed = True\n",
                "                 elif (next_high - entry_price) > (1.0 * atr) and stop_loss < entry_price:\n",
                "                      stop_loss = entry_price\n",
                "            elif position == -1:\n",
                "                 if next_high >= stop_loss:\n",
                "                      exit_price = stop_loss\n",
                "                      trade_closed = True\n",
                "                 elif (entry_price - next_low) > (1.0 * atr) and stop_loss > entry_price:\n",
                "                      stop_loss = entry_price\n",
                "                \n",
                "            if trade_closed:\n",
                "                if position == 1:\n",
                "                     gross_pnl = (exit_price - entry_price) * contract_size * lot_size\n",
                "                else:\n",
                "                     gross_pnl = (entry_price - exit_price) * contract_size * lot_size\n",
                "                     \n",
                "                net_pnl = gross_pnl - txn_cost\n",
                "                balance += net_pnl\n",
                "                trades.append(net_pnl)\n",
                "                position = 0\n",
                "        \n",
                "        if not trade_closed:\n",
                "            if action == 1: \n",
                "                if position == -1: \n",
                "                     exit_price = next_open\n",
                "                     gross_pnl = (entry_price - exit_price) * contract_size * lot_size\n",
                "                     net_pnl = gross_pnl - txn_cost\n",
                "                     balance += net_pnl\n",
                "                     trades.append(net_pnl)\n",
                "                     position = 1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price - (atr * 2.5)\n",
                "                elif position == 0:\n",
                "                     position = 1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price - (atr * 2.5)\n",
                "            elif action == 2: \n",
                "                if position == 1: \n",
                "                     exit_price = next_open\n",
                "                     gross_pnl = (exit_price - entry_price) * contract_size * lot_size\n",
                "                     net_pnl = gross_pnl - txn_cost\n",
                "                     balance += net_pnl\n",
                "                     trades.append(net_pnl)\n",
                "                     position = -1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price + (atr * 2.5)\n",
                "                elif position == 0:\n",
                "                     position = -1\n",
                "                     entry_price = next_open\n",
                "                     stop_loss = entry_price + (atr * 2.5)\n",
                "                     \n",
                "        equity_curve.append(balance)\n",
                "        \n",
                "    win_rate = sum(1 for t in trades if t > 0) / len(trades) * 100 if trades else 0\n",
                "    print(f\"\\nFinal Balance: ${balance:.2f}\")\n",
                "    print(f\"Total Trades: {len(trades)}\")\n",
                "    print(f\"Win Rate: {win_rate:.1f}%\")\n",
                "    \n",
                "    plt.figure(figsize=(12,6))\n",
                "    plt.plot(equity_curve)\n",
                "    plt.title(f\"Backtest Equity - {symbol}\")\n",
                "    plt.show()\n",
                "\n",
                "for symbol in Settings.PAIRS:\n",
                "     csv_path = os.path.join(drive_data_path, f\"{symbol}.csv\")\n",
                "     if os.path.exists(csv_path):\n",
                "         colab_backtest(symbol, csv_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}